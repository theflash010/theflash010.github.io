<!DOCTYPE html>
<html lang="en-gb"><head><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">VLLM_Worker | NAN blog</title>
<meta property="og:title" content="VLLM_Worker | NAN blog" />
<meta name="twitter:title" content="VLLM_Worker | NAN blog" />
<meta itemprop="name" content="VLLM_Worker | NAN blog" />
<meta name="application-name" content="VLLM_Worker | NAN blog" />
<meta property="og:site_name" content="NAN blog" />

<meta name="description" content="Record of Learning Journey">
<meta itemprop="description" content="Record of Learning Journey" />
<meta property="og:description" content="Record of Learning Journey" />
<meta name="twitter:description" content="Record of Learning Journey" />

<meta property="og:locale" content="en-gb" />
<meta name="language" content="en-gb" />

  <link rel="alternate" hreflang="en-gb" href="https://theflash010.github.io/posts/vllm_worker/" title="English" />





    
    
    

    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content=2025-04-15T21:42:12&#43;0800 />
    <meta property="article:published_time" content=2025-04-15T21:42:12&#43;0800 />
    <meta property="og:url" content="https://theflash010.github.io/posts/vllm_worker/" />

    
    <meta property="og:article:author" content="Nan Z" />
    <meta property="article:author" content="Nan Z" />
    <meta name="author" content="Nan Z" />
    
    

    

    <script defer type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "Article",
        "headline": "VLLM_Worker",
        "author": {
        "@type": "Person",
        "name": ""
        },
        "datePublished": "2025-04-15",
        "description": "",
        "wordCount":  6631 ,
        "mainEntityOfPage": "True",
        "dateModified": "2025-04-15",
        "image": {
        "@type": "imageObject",
        "url": ""
        },
        "publisher": {
        "@type": "Organization",
        "name": "NAN blog"
        }
    }
    </script>


<meta name="generator" content="Hugo 0.145.0">

    
    <meta property="og:url" content="https://theflash010.github.io/posts/vllm_worker/">
  <meta property="og:site_name" content="NAN blog">
  <meta property="og:title" content="VLLM_Worker">
  <meta property="og:description" content="VLLM Worker VLLM中的Worker是VLLM推理系统中非常重要的一个组件，每个Worker都对应一个物理上的gpu，Worker的职责是处理来自Executor发送的任务（一个Executor包含多个Worker），这其中包括预热推理引擎，执行模型推理等，并将任务结果返回给Executor。
Worker的定义与实例化 Worker的实例化发生在Executor的init中，在Executor的init中会根据并行化策略（TP，PP，DP）循环执行WorkerProc.make_worker_process函数。
Executor的init代码如下：
class MultiprocExecutor(Executor): def _init_executor(self) -&gt; None: #executor中有很多worker # Call self.shutdown at exit to clean up # and ensure workers will be terminated. self._finalizer = weakref.finalize(self, self.shutdown) # The child processes will send SIGUSR1 when unrecoverable # errors happen. def sigusr1_handler(signum, frame): logger.fatal( &#34;MulitprocExecutor got fatal signal from worker processes, &#34; &#34;shutting down. See stack trace above for root cause issue.&#34;) # Propagate error up to parent process. parent_process = psutil.Process().parent() parent_process.send_signal(signal.SIGUSR1) self.shutdown() signal.signal(signal.SIGUSR1, sigusr1_handler) self.world_size = self.parallel_config.world_size tensor_parallel_size = self.parallel_config.tensor_parallel_size assert self.world_size == tensor_parallel_size, ( f&#34;world_size ({self.world_size}) must be equal to the &#34; f&#34;tensor_parallel_size ({tensor_parallel_size}). &#34; f&#34;Pipeline parallelism is not yet implemented in v1&#34;) # Set multiprocessing envs that are common to V0 and V1 set_multiprocessing_worker_envs(self.parallel_config) # Multiprocessing-based executor does not support multi-node setting. # Since it only works for single node, we can use the loopback address # 127.0.0.1 for communication. distributed_init_method = get_distributed_init_method( &#34;127.0.0.1&#34;, get_open_port()) #找一个没人用的port # Initialize worker and set up message queues for SchedulerOutputs # and ModelRunnerOutputs self.rpc_broadcast_mq = MessageQueue(self.world_size, self.world_size) #vllm自定义的一个消息队列 使用ZMQ的PUB-SUB模式 创建SUB个数为world_size的消息队列 scheduler_output_handle = self.rpc_broadcast_mq.export_handle() #handle句柄包含了SUB订阅所需的信息 # Create workers self.workers: list[WorkerProcHandle] = [] for rank in range(self.world_size): #对所有的tp创建一个worker进程 worker = WorkerProc.make_worker_process(self.vllm_config, rank, rank, distributed_init_method, scheduler_output_handle) #消息队列句柄 self.workers.append(worker)#将worker进程的句柄（包括Worker创建的消息队列的句柄）加入workers中 # Ensure message queues are ready. Will deadlock if re-ordered # Must be kept consistent with the WorkerProc rpc_broadcast_mq是executor发给全体Worker的消息队列 worker_response_mq是Worker发送给executor的消息队列 self.rpc_broadcast_mq.wait_until_ready() #executor作为PUB 等待所有Worker作为SUB完成订阅 for w in self.workers:#每个Worker都会创建一个消息队列 w.worker_response_mq.wait_until_ready()#executor作为SUB 等待作为PUB的Worker发送信息&#34;READY&#34; WorkerProc.make_worker_process函数子进程，子进程执行WorkerProc.worker_main函数。WorkerProc.worker_main函数实例化WorkerProc对象">
  <meta property="og:locale" content="en_gb">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-15T21:42:12+08:00">
    <meta property="article:modified_time" content="2025-04-15T21:42:12+08:00">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="VLLM_Worker">
  <meta name="twitter:description" content="VLLM Worker VLLM中的Worker是VLLM推理系统中非常重要的一个组件，每个Worker都对应一个物理上的gpu，Worker的职责是处理来自Executor发送的任务（一个Executor包含多个Worker），这其中包括预热推理引擎，执行模型推理等，并将任务结果返回给Executor。
Worker的定义与实例化 Worker的实例化发生在Executor的init中，在Executor的init中会根据并行化策略（TP，PP，DP）循环执行WorkerProc.make_worker_process函数。
Executor的init代码如下：
class MultiprocExecutor(Executor): def _init_executor(self) -&gt; None: #executor中有很多worker # Call self.shutdown at exit to clean up # and ensure workers will be terminated. self._finalizer = weakref.finalize(self, self.shutdown) # The child processes will send SIGUSR1 when unrecoverable # errors happen. def sigusr1_handler(signum, frame): logger.fatal( &#34;MulitprocExecutor got fatal signal from worker processes, &#34; &#34;shutting down. See stack trace above for root cause issue.&#34;) # Propagate error up to parent process. parent_process = psutil.Process().parent() parent_process.send_signal(signal.SIGUSR1) self.shutdown() signal.signal(signal.SIGUSR1, sigusr1_handler) self.world_size = self.parallel_config.world_size tensor_parallel_size = self.parallel_config.tensor_parallel_size assert self.world_size == tensor_parallel_size, ( f&#34;world_size ({self.world_size}) must be equal to the &#34; f&#34;tensor_parallel_size ({tensor_parallel_size}). &#34; f&#34;Pipeline parallelism is not yet implemented in v1&#34;) # Set multiprocessing envs that are common to V0 and V1 set_multiprocessing_worker_envs(self.parallel_config) # Multiprocessing-based executor does not support multi-node setting. # Since it only works for single node, we can use the loopback address # 127.0.0.1 for communication. distributed_init_method = get_distributed_init_method( &#34;127.0.0.1&#34;, get_open_port()) #找一个没人用的port # Initialize worker and set up message queues for SchedulerOutputs # and ModelRunnerOutputs self.rpc_broadcast_mq = MessageQueue(self.world_size, self.world_size) #vllm自定义的一个消息队列 使用ZMQ的PUB-SUB模式 创建SUB个数为world_size的消息队列 scheduler_output_handle = self.rpc_broadcast_mq.export_handle() #handle句柄包含了SUB订阅所需的信息 # Create workers self.workers: list[WorkerProcHandle] = [] for rank in range(self.world_size): #对所有的tp创建一个worker进程 worker = WorkerProc.make_worker_process(self.vllm_config, rank, rank, distributed_init_method, scheduler_output_handle) #消息队列句柄 self.workers.append(worker)#将worker进程的句柄（包括Worker创建的消息队列的句柄）加入workers中 # Ensure message queues are ready. Will deadlock if re-ordered # Must be kept consistent with the WorkerProc rpc_broadcast_mq是executor发给全体Worker的消息队列 worker_response_mq是Worker发送给executor的消息队列 self.rpc_broadcast_mq.wait_until_ready() #executor作为PUB 等待所有Worker作为SUB完成订阅 for w in self.workers:#每个Worker都会创建一个消息队列 w.worker_response_mq.wait_until_ready()#executor作为SUB 等待作为PUB的Worker发送信息&#34;READY&#34; WorkerProc.make_worker_process函数子进程，子进程执行WorkerProc.worker_main函数。WorkerProc.worker_main函数实例化WorkerProc对象">


    

    <link rel="canonical" href="https://theflash010.github.io/posts/vllm_worker/">
    <link href="/style.min.2d921c18cf1ec555ffc03d59a8adc211c402c68c930c27d6a0c306ab175a8d09.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="https://theflash010.github.io/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
    
</head>
<body data-theme = "auto" class="notransition">

<script src="/js/theme.min.8961c317c5b88b953fe27525839672c9343f1058ab044696ca225656c8ba2ab0.js" integrity="sha256-iWHDF8W4i5U/4nUlg5ZyyTQ/EFirBEaWyiJWVsi6KrA="></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="https://theflash010.github.io/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title>Home</title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link active" href="/posts/">
                        Posts
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/pages/about/">
                        About
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">VLLM_Worker</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2025-04-15T21:42:12&#43;08:00" itemprop="datePublished"> 15 Apr 2025 </time>
                </div>
                
            </header>
            
    
    <details class="toc" ZgotmplZ>
        <summary><b>Table of Contents</b></summary>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#worker的定义与实例化">Worker的定义与实例化</a>
      <ul>
        <li><a href="#worker-初始化设备">Worker 初始化设备</a>
          <ul>
            <li><a href="#初始化分布式环境">初始化分布式环境</a></li>
            <li><a href="#实例化model_runner">实例化model_runner</a></li>
          </ul>
        </li>
        <li><a href="#worker加载参数">Worker加载参数</a></li>
      </ul>
    </li>
    <li><a href="#worker的工作流">Worker的工作流</a>
      <ul>
        <li><a href="#messagequeue">MessageQueue</a></li>
        <li><a href="#executor--worker--消息队列">Executor &lt;&ndash;&gt; Worker  消息队列</a>
          <ul>
            <li><a href="#executor作为pubworker作为sub">Executor作为PUB，Worker作为SUB</a></li>
            <li><a href="#worker作为pubexecutor作为sub">Worker作为PUB，Executor作为SUB</a></li>
          </ul>
        </li>
        <li><a href="#工作流程">工作流程</a>
          <ul>
            <li><a href="#worker_busy_loop">worker_busy_loop</a></li>
            <li><a href="#enginecore-executor-worker-model_runner-forward">EngineCore-&gt;Executor-&gt;Worker-&gt;model_runner-&gt;forward</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
    </details>
            <div class="page-content">
                <h1 id="vllm-worker">VLLM Worker</h1>
<p>VLLM中的Worker是VLLM推理系统中非常重要的一个组件，每个Worker都对应一个物理上的gpu，Worker的职责是处理来自Executor发送的任务（一个Executor包含多个Worker），这其中包括预热推理引擎，执行模型推理等，并将任务结果返回给Executor。</p>
<img src=".\image-20250415222935321.png" alt="image-20250415222935321" style="zoom: 67%;" />
<h2 id="worker的定义与实例化">Worker的定义与实例化</h2>
<p>Worker的实例化发生在Executor的init中，在Executor的init中会根据并行化策略（TP，PP，DP）循环执行WorkerProc.make_worker_process函数。</p>
<p>Executor的init代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MultiprocExecutor</span><span class="p">(</span><span class="n">Executor</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_init_executor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span> <span class="c1">#executor中有很多worker</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Call self.shutdown at exit to clean up</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and ensure workers will be terminated.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_finalizer</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># The child processes will send SIGUSR1 when unrecoverable</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># errors happen.</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">sigusr1_handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;MulitprocExecutor got fatal signal from worker processes, &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;shutting down. See stack trace above for root cause issue.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Propagate error up to parent process.</span>
</span></span><span class="line"><span class="cl">            <span class="n">parent_process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">parent_process</span><span class="o">.</span><span class="n">send_signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">,</span> <span class="n">sigusr1_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">tensor_parallel_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">tensor_parallel_size</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="n">tensor_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;world_size (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="s2">) must be equal to the &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;tensor_parallel_size (</span><span class="si">{</span><span class="n">tensor_parallel_size</span><span class="si">}</span><span class="s2">). &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;Pipeline parallelism is not yet implemented in v1&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Set multiprocessing envs that are common to V0 and V1</span>
</span></span><span class="line"><span class="cl">        <span class="n">set_multiprocessing_worker_envs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Multiprocessing-based executor does not support multi-node setting.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Since it only works for single node, we can use the loopback address</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 127.0.0.1 for communication.</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span> <span class="o">=</span> <span class="n">get_distributed_init_method</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;127.0.0.1&#34;</span><span class="p">,</span> <span class="n">get_open_port</span><span class="p">())</span>  <span class="c1">#找一个没人用的port</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize worker and set up message queues for SchedulerOutputs</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and ModelRunnerOutputs</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span> <span class="c1">#vllm自定义的一个消息队列 使用ZMQ的PUB-SUB模式 创建SUB个数为world_size的消息队列</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">export_handle</span><span class="p">()</span> <span class="c1">#handle句柄包含了SUB订阅所需的信息</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Create workers</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">WorkerProcHandle</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">):</span> <span class="c1">#对所有的tp创建一个worker进程</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="o">.</span><span class="n">make_worker_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                                    <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">scheduler_output_handle</span><span class="p">)</span>  <span class="c1">#消息队列句柄</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">worker</span><span class="p">)</span><span class="c1">#将worker进程的句柄（包括Worker创建的消息队列的句柄）加入workers中</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Ensure message queues are ready. Will deadlock if re-ordered</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Must be kept consistent with the WorkerProc      rpc_broadcast_mq是executor发给全体Worker的消息队列   worker_response_mq是Worker发送给executor的消息队列</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span> <span class="c1">#executor作为PUB 等待所有Worker作为SUB完成订阅</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span><span class="c1">#每个Worker都会创建一个消息队列</span>
</span></span><span class="line"><span class="cl">            <span class="n">w</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span><span class="c1">#executor作为SUB 等待作为PUB的Worker发送信息&#34;READY&#34;</span>
</span></span></code></pre></div><p>WorkerProc.make_worker_process函数子进程，子进程执行WorkerProc.worker_main函数。WorkerProc.worker_main函数实例化WorkerProc对象</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">make_worker_process</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_shm_handle</span><span class="p">,</span>  <span class="c1">#消息队列句柄</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WorkerProcHandle</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">get_mp_context</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ZMQ path for worker to send ready message and shm_broadcast handle</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># back to core process.</span>
</span></span><span class="line"><span class="cl">        <span class="n">ready_path</span> <span class="o">=</span> <span class="n">get_open_zmq_ipc_path</span><span class="p">()</span><span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">process_kwargs</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;vllm_config&#34;</span><span class="p">:</span> <span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;local_rank&#34;</span><span class="p">:</span> <span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;rank&#34;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed_init_method&#34;</span><span class="p">:</span> <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;input_shm_handle&#34;</span><span class="p">:</span> <span class="n">input_shm_handle</span><span class="p">,</span> <span class="c1"># 消息队列句柄</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ready_path&#34;</span><span class="p">:</span> <span class="n">ready_path</span><span class="p">,</span> <span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Run EngineCore busy loop in background process.</span>
</span></span><span class="line"><span class="cl">        <span class="n">proc</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">worker_main</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">kwargs</span><span class="o">=</span><span class="n">process_kwargs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#定义进程</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span><span class="c1">#开启进程 执行worker_main函数</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Wait for startup</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq_handle</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="o">.</span><span class="n">wait_for_startup</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">proc</span><span class="p">,</span> <span class="n">ready_path</span><span class="p">)</span><span class="c1">#等待Worker中通过ready_path发送&#34;READY&#34; 并且接收Worker创建的消息队列的句柄</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_handle</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker_response_mq_handle</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="c1">#作为Worker创建的消息队列的SUB成员</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">WorkerProcHandle</span><span class="p">(</span><span class="n">proc</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">ready_path</span><span class="p">,</span> <span class="n">worker_response_mq</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">worker_main</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="c1">#**kwargs包括 &#34;input_shm_handle&#34; 消息队列句柄</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34; Worker initialization and execution loops.
</span></span></span><span class="line"><span class="cl"><span class="s2">        This runs a background process &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Signal handler used for graceful termination.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># SystemExit exception is only raised once to allow this and worker</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># processes to terminate without error</span>
</span></span><span class="line"><span class="cl">        <span class="n">shutdown_requested</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">signal_handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">nonlocal</span> <span class="n">shutdown_requested</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="ow">not</span> <span class="n">shutdown_requested</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">shutdown_requested</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">                <span class="k">raise</span> <span class="ne">SystemExit</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Either SIGTERM or SIGINT will terminate the worker</span>
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">,</span> <span class="n">signal_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">worker</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1">#开启worker进程</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Ensure message queues are ready. Will deadlock if re-ordered.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Must be kept consistent with the Executor</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span> <span class="c1">#worker作为SUB 等待作为PUB的executor作为PUB发来&#34;READY&#34;消息</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span><span class="c1">#worker作为PUB 等待所有作为SUB的订阅消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">worker</span><span class="o">.</span><span class="n">worker_busy_loop</span><span class="p">()</span> <span class="c1">#worker准备完毕，不断loop运行推理工作</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">SystemExit</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&#34;Worker interrupted.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># worker_busy_loop sends exceptions exceptons to Executor</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># for shutdown, but if there is an error in startup or an</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># error with IPC itself, we need to alert the parent.</span>
</span></span><span class="line"><span class="cl">            <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span><span class="o">.</span><span class="n">send_signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">finally</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Clean up once worker exits busy loop</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">worker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">worker</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">worker</span> <span class="o">=</span> <span class="kc">None</span>
</span></span></code></pre></div><p>WorkerProc包括一个WorkerWrapper，这个类是Worker的一个套壳前端</p>
<p>在 wrapper.init_worker(all_kwargs) 这个函数执行后，真正的Worker才被实例化，Worker中有device，model_runner等属性（其实是父类WorkerBase的属性）</p>
<p>Worker实例化之后还需要进行self.worker.init_device()和self.worker.load_model()函数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">WorkerProc</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Wrapper that runs one Worker in a separate process.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">READY_STR</span> <span class="o">=</span> <span class="s2">&#34;READY&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">input_shm_handle</span><span class="p">:</span> <span class="n">Handle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">ready_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
</span></span><span class="line"><span class="cl">        <span class="n">wrapper</span> <span class="o">=</span> <span class="n">WorkerWrapperBase</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">,</span> <span class="n">rpc_rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span> <span class="c1">#worker的一个封装管理器</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># TODO: move `init_worker` to executor level as a collective rpc call</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_kwargs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="p">{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_kwargs</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;vllm_config&#34;</span><span class="p">:</span> <span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;local_rank&#34;</span><span class="p">:</span> <span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;rank&#34;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed_init_method&#34;</span><span class="p">:</span> <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;is_driver_worker&#34;</span><span class="p">:</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">wrapper</span><span class="o">.</span><span class="n">init_worker</span><span class="p">(</span><span class="n">all_kwargs</span><span class="p">)</span> <span class="c1">#这里通过wrapper套壳进行worker真正的实例化，但仅仅实例化，还没加载参数，初始化分布式环境等</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span> <span class="o">=</span> <span class="n">wrapper</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">_add_prefix</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;VllmWorker rank=</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_add_prefix</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;VllmWorker rank=</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize MessageQueue for receiving SchedulerOutput</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_handle</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_shm_handle</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span> <span class="c1">#用消息队列句柄中的信息作为SUB 订阅PUB 隐式发送订阅消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initializes a message queue for sending the model output</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="c1">#创建SUB个数为1的消息队列，SUB就是executor</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">export_handle</span><span class="p">()</span><span class="c1">#Worker创建的消息队列的句柄</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Send Readiness signal to EngineCore process.</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">zmq_socket_ctx</span><span class="p">(</span><span class="n">ready_path</span><span class="p">,</span> <span class="n">zmq</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">PUSH</span><span class="p">)</span> <span class="k">as</span> <span class="n">ready_socket</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">payload</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">worker_response_mq_handle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span><span class="c1">#将Worker创建的消息队列的句柄转化为二进制数据</span>
</span></span><span class="line"><span class="cl">            <span class="n">ready_socket</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">READY_STR</span><span class="p">)</span><span class="c1">#用ready_path发送WorkerProc.READY_STR 就是字符串&#34;READY&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="n">ready_socket</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span><span class="c1">#发送句柄数据</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">init_device</span><span class="p">()</span>  <span class="c1">#worker与gpu绑定+初始化分布式环境，实例化多个通信组</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>   <span class="c1">#worker通过model_runner执行实例化模型对象，模型参数加载</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">WorkerWrapperBase</span><span class="p">:</span> <span class="c1">#Worker的封装管理器，负责worker的延迟初始化和环境配置</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    This class represents one process in an executor/engine. It is responsible
</span></span></span><span class="line"><span class="cl"><span class="s2">    for lazily initializing the worker and handling the worker&#39;s lifecycle.
</span></span></span><span class="line"><span class="cl"><span class="s2">    We first instantiate the WorkerWrapper, which remembers the worker module
</span></span></span><span class="line"><span class="cl"><span class="s2">    and class name. Then, when we call `update_environment_variables`, and the
</span></span></span><span class="line"><span class="cl"><span class="s2">    real initialization happens in `init_worker`.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">rpc_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1">#rpc_rank是worker在executor中的rank，不是分布式的rank</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        Initialize the worker wrapper with the given vllm_config and rpc_rank.
</span></span></span><span class="line"><span class="cl"><span class="s2">        Note: rpc_rank is the rank of the worker in the executor. In most cases,
</span></span></span><span class="line"><span class="cl"><span class="s2">        it is also the rank of the worker in the distributed group. However,
</span></span></span><span class="line"><span class="cl"><span class="s2">        when multiple executors work together, they can be different.
</span></span></span><span class="line"><span class="cl"><span class="s2">        e.g. in the case of SPMD-style offline inference with TP=2,
</span></span></span><span class="line"><span class="cl"><span class="s2">        users can launch 2 engines/executors, each with only 1 worker.
</span></span></span><span class="line"><span class="cl"><span class="s2">        All workers have rpc_rank=0, but they have different ranks in the TP
</span></span></span><span class="line"><span class="cl"><span class="s2">        group.
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_rank</span> <span class="o">=</span> <span class="n">rpc_rank</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">WorkerBase</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># do not store this `vllm_config`, `init_worker` will set the final</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># one. TODO: investigate if we can remove this field in</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># `WorkerWrapperBase`, `init_cached_hf_modules` should be</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># unnecessary now.</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">model_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># it can be None in tests</span>
</span></span><span class="line"><span class="cl">            <span class="n">trust_remote_code</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">trust_remote_code</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">trust_remote_code</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># note: lazy import to avoid importing torch before initializing</span>
</span></span><span class="line"><span class="cl">                <span class="kn">from</span> <span class="nn">vllm.utils</span> <span class="kn">import</span> <span class="n">init_cached_hf_modules</span>
</span></span><span class="line"><span class="cl">                <span class="n">init_cached_hf_modules</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">init_worker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">all_kwargs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        Here we inject some common logic before initializing the worker.
</span></span></span><span class="line"><span class="cl"><span class="s2">        Arguments are passed to the worker class constructor.
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">all_kwargs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rpc_rank</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;vllm_config&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;vllm_config is required to initialize the worker&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">enable_trace_function_call_for_thread</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">vllm.plugins</span> <span class="kn">import</span> <span class="n">load_general_plugins</span>
</span></span><span class="line"><span class="cl">        <span class="n">load_general_plugins</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">worker_cls</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker_class</span> <span class="o">=</span> <span class="n">resolve_obj_by_qualname</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">worker_cls</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;passing worker_cls as a class object is strongly deprecated,&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34; as the serialization of class objects can be tricky and&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34; error-prone. To be safe, please keep the class in a separate&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34; module and pass the qualified name of the class as a string.&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">worker_cls</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                              <span class="nb">bytes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker_class</span> <span class="o">=</span> <span class="n">cloudpickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">worker_cls</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">worker_extension_cls</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker_extension_cls</span> <span class="o">=</span> <span class="n">resolve_obj_by_qualname</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">worker_extension_cls</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">extended_calls</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">worker_extension_cls</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">worker_class</span><span class="o">.</span><span class="vm">__bases__</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># check any conflicts between worker and worker_extension_cls</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">worker_extension_cls</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">attr</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&#34;__&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                    <span class="k">assert</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">worker_class</span><span class="p">,</span> <span class="n">attr</span><span class="p">),</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                        <span class="sa">f</span><span class="s2">&#34;Worker class </span><span class="si">{</span><span class="n">worker_class</span><span class="si">}</span><span class="s2"> already has an attribute&#34;</span>
</span></span><span class="line"><span class="cl">                        <span class="sa">f</span><span class="s2">&#34; </span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">, which conflicts with the worker&#34;</span>
</span></span><span class="line"><span class="cl">                        <span class="sa">f</span><span class="s2">&#34; extension class </span><span class="si">{</span><span class="n">worker_extension_cls</span><span class="si">}</span><span class="s2">.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">worker_extension_cls</span><span class="p">,</span> <span class="n">attr</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">                        <span class="n">extended_calls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># dynamically inherit the worker extension class</span>
</span></span><span class="line"><span class="cl">                <span class="n">worker_class</span><span class="o">.</span><span class="vm">__bases__</span> <span class="o">=</span> <span class="n">worker_class</span><span class="o">.</span><span class="vm">__bases__</span> <span class="o">+</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">worker_extension_cls</span><span class="p">,</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;Injected </span><span class="si">%s</span><span class="s2"> into </span><span class="si">%s</span><span class="s2"> for extended collective_rpc calls </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">worker_extension_cls</span><span class="p">,</span> <span class="n">worker_class</span><span class="p">,</span> <span class="n">extended_calls</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">set_current_vllm_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># To make vLLM config available during worker initialization</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">worker</span> <span class="o">=</span> <span class="n">worker_class</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1">#vllm.v1.worker.gpu_worker.Worker wrapper中真正实例化worker</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Worker</span><span class="p">(</span><span class="n">WorkerBase</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">is_driver_worker</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">distributed_init_method</span><span class="o">=</span><span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">is_driver_worker</span><span class="o">=</span><span class="n">is_driver_worker</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">trust_remote_code</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># note: lazy import to avoid importing torch before initializing</span>
</span></span><span class="line"><span class="cl">            <span class="kn">from</span> <span class="nn">vllm.utils</span> <span class="kn">import</span> <span class="n">init_cached_hf_modules</span>
</span></span><span class="line"><span class="cl">            <span class="n">init_cached_hf_modules</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Torch profiler. Enabled and configured through env vars:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># VLLM_TORCH_PROFILER_DIR=/path/to/save/trace</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">envs</span><span class="o">.</span><span class="n">VLLM_TORCH_PROFILER_DIR</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch_profiler_trace_dir</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">VLLM_TORCH_PROFILER_DIR</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;Profiling enabled. Traces will be saved to: </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">torch_profiler_trace_dir</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">activities</span><span class="o">=</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">                    <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">on_trace_ready</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tensorboard_trace_handler</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">torch_profiler_trace_dir</span><span class="p">,</span> <span class="n">use_gzip</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">WorkerBase</span><span class="p">(</span><span class="n">WorkerBaseV0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Abstract class for v1 worker, mainly define some methods for v1.
</span></span></span><span class="line"><span class="cl"><span class="s2">    For methods shared by v0 and v1, define them in v0 WorkerBase
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">is_driver_worker</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        Initialize common worker components.
</span></span></span><span class="line"><span class="cl"><span class="s2">        
</span></span></span><span class="line"><span class="cl"><span class="s2">        Args:
</span></span></span><span class="line"><span class="cl"><span class="s2">            vllm_config: Complete vLLM configuration
</span></span></span><span class="line"><span class="cl"><span class="s2">            local_rank: Local device index
</span></span></span><span class="line"><span class="cl"><span class="s2">            rank: Global rank in distributed setup
</span></span></span><span class="line"><span class="cl"><span class="s2">            distributed_init_method: Distributed initialization method
</span></span></span><span class="line"><span class="cl"><span class="s2">            is_driver_worker: Whether this worker handles driver 
</span></span></span><span class="line"><span class="cl"><span class="s2">            responsibilities
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Configuration storage</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">distributed_init_method</span> <span class="o">=</span> <span class="n">distributed_init_method</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">is_driver_worker</span> <span class="o">=</span> <span class="n">is_driver_worker</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Device and model state</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model_runner</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="n">None2</span>
</span></span></code></pre></div><h3 id="worker-初始化设备">Worker 初始化设备</h3>
<p>对于self.worker.init_device()，依然需要wrapper的套壳，实际上执行worker类的init_device</p>
<p>在init_device中进行了</p>
<ol>
<li>绑定设备（很简单）</li>
<li>初始化分布式环境，实例化多个通信组</li>
<li>实例化model_runner</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">init_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1">#这里是wrapper类的代码</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">set_current_vllm_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># To make vLLM config available during device initialization</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">init_device</span><span class="p">()</span>  <span class="c1"># type: ignore   wrapper内的worker执行init_device</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">init_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1">#这里是worker类代码</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_config</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&#34;cuda&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># torch.distributed.all_reduce does not free the input tensor until</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># the synchronization point. This causes the memory usage to grow</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># as the number of all_reduce calls increases. This env var disables</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># this behavior.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Related issue:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># https://discuss.pytorch.org/t/cuda-allocation-lifetime-for-inputs-to-distributed-all-reduce/191573</span>
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;TORCH_NCCL_AVOID_RECORD_STREAMS&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;1&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># This env var set by Ray causes exceptions with graph building.</span>
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&#34;NCCL_ASYNC_ERROR_HANDLING&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="c1">#定义设备</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1">#绑定设备</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">_check_if_gpu_supports_dtype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">init_gpu_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">mem_get_info</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="sa">f</span><span class="s2">&#34;Not support device type: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device_config</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize the distributed environment. 初始化分布式环境，实例化多个通信组</span>
</span></span><span class="line"><span class="cl">        <span class="n">init_worker_distributed_environment</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="bp">self</span><span class="o">.</span><span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Set random seed.</span>
</span></span><span class="line"><span class="cl">        <span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Construct the model runner</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model_runner</span><span class="p">:</span> <span class="n">GPUModelRunner</span> <span class="o">=</span> <span class="n">GPUModelRunner</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1">#获取模型有关参数，包括注意力头数量(TP)，hidden_size     预分配一些推理时需要的空间，包括input_batch，inputs_embeds等</span>
</span></span></code></pre></div><h4 id="初始化分布式环境">初始化分布式环境</h4>
<p>初始化分布式环境做的工作包括：</p>
<ol>
<li>初始化全局分布式通信组环境_WORLD</li>
<li>初始化模型并行环境，包括_TP，_PP等内部通信组环境</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">init_worker_distributed_environment</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">parallel_config</span><span class="p">:</span> <span class="n">ParallelConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">distributed_init_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Initialize the distributed environment.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">set_custom_all_reduce</span><span class="p">(</span><span class="ow">not</span> <span class="n">parallel_config</span><span class="o">.</span><span class="n">disable_custom_all_reduce</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">init_distributed_environment</span><span class="p">(</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                 <span class="n">distributed_init_method</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">)</span> <span class="c1">#初始化全局分布式通信组环境_WORLD</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">ensure_model_parallel_initialized</span><span class="p">(</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">tensor_parallel_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                      <span class="n">parallel_config</span><span class="o">.</span><span class="n">pipeline_parallel_size</span><span class="p">)</span> <span class="c1">#初始化模型并行环境，包括_TP,_PP等内部通信组环境</span>
</span></span></code></pre></div><h5 id="1初始化全局分布式通信环境_world">1.初始化全局分布式通信环境_WORLD</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">init_distributed_environment</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1">#单机器内的world_size 也就是单个dp的world_size</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>        <span class="c1">#单机器内的rank</span>
</span></span><span class="line"><span class="cl">    <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;env://&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;nccl&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;world_size=</span><span class="si">%d</span><span class="s2"> rank=</span><span class="si">%d</span><span class="s2"> local_rank=</span><span class="si">%d</span><span class="s2"> &#34;</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;distributed_init_method=</span><span class="si">%s</span><span class="s2"> backend=</span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">vllm.config</span> <span class="kn">import</span> <span class="n">get_current_vllm_config</span>
</span></span><span class="line"><span class="cl">    <span class="n">config</span> <span class="o">=</span> <span class="n">get_current_vllm_config</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">data_parallel_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>   <span class="c1">#考虑dp的情况</span>
</span></span><span class="line"><span class="cl">        <span class="n">parallel_config</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">parallel_config</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># adjust to take into account data parallelism</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># offset the rank by the data parallel rank</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span> <span class="o">=</span> <span class="n">parallel_config</span><span class="o">.</span><span class="n">data_parallel_rank</span> <span class="o">*</span> <span class="n">world_size</span> <span class="o">+</span> <span class="n">rank</span>  <span class="c1">#全局rank,考虑dp+tp</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># adjust the world size to take into account data parallelism</span>
</span></span><span class="line"><span class="cl">        <span class="n">world_size</span> <span class="o">=</span> <span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size_across_dp</span>   <span class="c1">#全局world_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">ip</span> <span class="o">=</span> <span class="n">parallel_config</span><span class="o">.</span><span class="n">data_parallel_master_ip</span>
</span></span><span class="line"><span class="cl">        <span class="n">port</span> <span class="o">=</span> <span class="n">parallel_config</span><span class="o">.</span><span class="n">get_next_dp_init_port</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;tcp://</span><span class="si">{</span><span class="n">ip</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">&#34;</span>  <span class="c1"># noqa</span>
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;Adjusting world_size=</span><span class="si">%d</span><span class="s2"> rank=</span><span class="si">%d</span><span class="s2"> distributed_init_method=</span><span class="si">%s</span><span class="s2"> for DP&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">world_size</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">distributed_init_method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">distributed_init_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed_init_method must be provided when initializing &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed environment&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># this backend is used for WORLD</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">init_method</span><span class="o">=</span><span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># set the local rank</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># local_rank is not available in torch ProcessGroup,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># see https://github.com/pytorch/pytorch/issues/122816</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">local_rank</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># local rank not set, this usually happens in single-node</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># setting, where we can use rank as local rank</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">distributed_init_method</span> <span class="o">==</span> <span class="s2">&#34;env://&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_rank</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">LOCAL_RANK</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_rank</span> <span class="o">=</span> <span class="n">rank</span>
</span></span><span class="line"><span class="cl">    <span class="k">global</span> <span class="n">_WORLD</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">_WORLD</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()))</span> <span class="c1">#只有单个元素的列表，元素是全局的world_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">_WORLD</span> <span class="o">=</span> <span class="n">init_world_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">local_rank</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span>  <span class="c1">#_WORLD就是全局通信组，是必要的基础设施</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">_WORLD</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">(),</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;world group already initialized with a different world size&#34;</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="2初始化模型并行环境包括_tp_pp等内部通信组环境">2.初始化模型并行环境，包括_TP，_PP等内部通信组环境</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">ensure_model_parallel_initialized</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Helper to initialize model parallel groups if they are not initialized,
</span></span></span><span class="line"><span class="cl"><span class="s2">    or ensure tensor-parallel and pipeline-parallel sizes are equal to expected
</span></span></span><span class="line"><span class="cl"><span class="s2">    values if the model parallel groups are initialized.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">model_parallel_is_initialized</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">initialize_model_parallel</span><span class="p">(</span><span class="n">tensor_model_parallel_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">pipeline_model_parallel_size</span><span class="p">,</span> <span class="n">backend</span><span class="p">)</span> <span class="c1">#初始化_TP _PP</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">get_tensor_model_parallel_world_size</span><span class="p">()</span> <span class="o">==</span> <span class="n">tensor_model_parallel_size</span>
</span></span><span class="line"><span class="cl">    <span class="p">),</span> <span class="p">(</span><span class="s2">&#34;tensor parallel group already initialized, but of unexpected size: &#34;</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">get_tensor_model_parallel_world_size</span><span class="p">()</span><span class="si">=}</span><span class="s2"> vs. &#34;</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">tensor_model_parallel_size</span><span class="si">=}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">pp_world_size</span> <span class="o">=</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">world_size</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="p">(</span><span class="n">pp_world_size</span> <span class="o">==</span> <span class="n">pipeline_model_parallel_size</span><span class="p">),</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;pipeline parallel group already initialized, but of unexpected size: &#34;</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">pp_world_size</span><span class="si">=}</span><span class="s2"> vs. &#34;</span>
</span></span><span class="line"><span class="cl">        <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="n">pipeline_model_parallel_size</span><span class="si">=}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">initialize_model_parallel</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">tensor_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">pipeline_model_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">backend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Initialize model parallel groups.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Arguments:
</span></span></span><span class="line"><span class="cl"><span class="s2">        tensor_model_parallel_size: number of GPUs used for tensor model
</span></span></span><span class="line"><span class="cl"><span class="s2">            parallelism.
</span></span></span><span class="line"><span class="cl"><span class="s2">        pipeline_model_parallel_size: number of GPUs used for pipeline model
</span></span></span><span class="line"><span class="cl"><span class="s2">            parallelism.
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">    Let&#39;s say we have a total of 8 GPUs denoted by g0 ... g7 and we
</span></span></span><span class="line"><span class="cl"><span class="s2">    use 2 GPUs to parallelize the model tensor, and 4 GPUs to parallelize
</span></span></span><span class="line"><span class="cl"><span class="s2">    the model pipeline. The present function will
</span></span></span><span class="line"><span class="cl"><span class="s2">    create 4 tensor model-parallel groups and 2 pipeline model-parallel groups:
</span></span></span><span class="line"><span class="cl"><span class="s2">        4 tensor model-parallel groups:
</span></span></span><span class="line"><span class="cl"><span class="s2">            [g0, g1], [g2, g3], [g4, g5], [g6, g7]
</span></span></span><span class="line"><span class="cl"><span class="s2">        2 pipeline model-parallel groups:
</span></span></span><span class="line"><span class="cl"><span class="s2">            [g0, g2, g4, g6], [g1, g3, g5, g7]
</span></span></span><span class="line"><span class="cl"><span class="s2">    Note that for efficiency, the caller should make sure adjacent ranks
</span></span></span><span class="line"><span class="cl"><span class="s2">    are on the same DGX box. For example if we are using 2 DGX-1 boxes
</span></span></span><span class="line"><span class="cl"><span class="s2">    with a total of 16 GPUs, rank 0 to 7 belong to the first box and
</span></span></span><span class="line"><span class="cl"><span class="s2">    ranks 8 to 15 belong to the second box.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Get world size and rank. Ensure some consistencies.</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">backend</span> <span class="o">=</span> <span class="n">backend</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">data_parallel_size</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="kn">from</span> <span class="nn">vllm.config</span> <span class="kn">import</span> <span class="n">get_current_vllm_config</span>
</span></span><span class="line"><span class="cl">    <span class="n">config</span> <span class="o">=</span> <span class="n">get_current_vllm_config</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">data_parallel_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">data_parallel_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># the layout order is: ExternalDP x DP x PP x TP</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># ExternalDP is the data parallel group that is not part of the model,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># every dp rank can generate independently (in verl integration).</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># DP is the data parallel group that is part of the model,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># all the ranks in the same DP group should generate simultaneously,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># i.e. the `generate` call in the same DP group should be called together,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># otherwise it will cause deadlock.</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># to get group_ranks for each dimension, transpose that dimension to the</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># last dimension, then reshape to 2D, then unbind the last dimension</span>
</span></span><span class="line"><span class="cl">    <span class="n">all_ranks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">world_size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">data_parallel_size</span><span class="p">,</span> <span class="n">pipeline_model_parallel_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">tensor_model_parallel_size</span><span class="p">)</span>  <span class="c1"># noqa</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Build the tensor model-parallel groups.</span>
</span></span><span class="line"><span class="cl">    <span class="k">global</span> <span class="n">_TP</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">_TP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s2">&#34;tensor model parallel group is already initialized&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span> <span class="o">=</span> <span class="n">all_ranks</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensor_model_parallel_size</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1">#确定tp的rank分组情况</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># message queue broadcaster is only used in tensor model parallel group</span>
</span></span><span class="line"><span class="cl">    <span class="n">_TP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span><span class="n">group_ranks</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">backend</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">group_name</span><span class="o">=</span><span class="s2">&#34;tp&#34;</span><span class="p">)</span> <span class="c1">#实例化内部tp通信组</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Build the pipeline model-parallel groups.</span>
</span></span><span class="line"><span class="cl">    <span class="k">global</span> <span class="n">_PP</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">_PP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;pipeline model parallel group is already initialized&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span> <span class="o">=</span> <span class="n">all_ranks</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">pipeline_model_parallel_size</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">]</span>  <span class="c1">#确定tp的rank分组情况</span>
</span></span><span class="line"><span class="cl">    <span class="n">_PP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span><span class="n">group_ranks</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">backend</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">group_name</span><span class="o">=</span><span class="s2">&#34;pp&#34;</span><span class="p">)</span> <span class="c1">#实例化内部pp通信组</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">global</span> <span class="n">_DP</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">_DP</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="s2">&#34;data parallel group is already initialized&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span> <span class="o">=</span> <span class="n">all_ranks</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                      <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                 <span class="n">data_parallel_size</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">]</span> <span class="c1">#确定dp的rank分组情况</span>
</span></span><span class="line"><span class="cl">    <span class="n">_DP</span> <span class="o">=</span> <span class="n">init_model_parallel_group</span><span class="p">(</span><span class="n">group_ranks</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">get_world_group</span><span class="p">()</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">backend</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                    <span class="n">group_name</span><span class="o">=</span><span class="s2">&#34;dp&#34;</span><span class="p">)</span> <span class="c1">#实例化内部dp通信组</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;rank </span><span class="si">%s</span><span class="s2"> in world size </span><span class="si">%s</span><span class="s2"> is assigned as &#34;</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;DP rank </span><span class="si">%s</span><span class="s2">, PP rank </span><span class="si">%s</span><span class="s2">, TP rank </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">_DP</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="n">_PP</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">,</span> <span class="n">_TP</span><span class="o">.</span><span class="n">rank_in_group</span><span class="p">)</span>
</span></span></code></pre></div><h5 id="3groupcoordinator是什么">3.GroupCoordinator是什么</h5>
<p>init_model_parallel_group会生成通信组GroupCoordinator</p>
<p>GroupCoordinator是vllm自己写的通信组，当然底层通信使用的还是torch.distributed</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">init_model_parallel_group</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GroupCoordinator</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">GroupCoordinator</span><span class="p">(</span> <span class="c1">#vllm自己实现的通信组</span>
</span></span><span class="line"><span class="cl">        <span class="n">group_ranks</span><span class="o">=</span><span class="n">group_ranks</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch_distributed_backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span> <span class="c1">#一般是&#34;NCCL&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_device_communicator</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_message_queue_broadcaster</span><span class="o">=</span><span class="n">use_message_queue_broadcaster</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">group_name</span><span class="o">=</span><span class="n">group_name</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GroupCoordinator</span><span class="p">:</span>  <span class="c1">#通信组，包括_WORLD,_TP,_PP,支持all_reduce等通信操作</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    PyTorch ProcessGroup wrapper for a group of processes.
</span></span></span><span class="line"><span class="cl"><span class="s2">    PyTorch ProcessGroup is bound to one specific communication backend,
</span></span></span><span class="line"><span class="cl"><span class="s2">        e.g. NCCL, Gloo, MPI, etc.
</span></span></span><span class="line"><span class="cl"><span class="s2">    GroupCoordinator takes charge of all the communication operations among
</span></span></span><span class="line"><span class="cl"><span class="s2">        the processes in the group. It manages both CPU and device
</span></span></span><span class="line"><span class="cl"><span class="s2">        communication.
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># available attributes:</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># global rank</span>
</span></span><span class="line"><span class="cl">    <span class="n">ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>  <span class="c1"># global ranks in the group</span>
</span></span><span class="line"><span class="cl">    <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># size of the group</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># difference between `local_rank` and `rank_in_group`:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># if we have a group of size 4 across two nodes:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Process | Node | Rank | Local Rank | Rank in Group</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#   0     |   0  |  0   |     0      |       0</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#   1     |   0  |  1   |     1      |       1</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#   2     |   1  |  2   |     0      |       2</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#   3     |   1  |  3   |     1      |       3</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># local rank used to assign devices</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank_in_group</span><span class="p">:</span> <span class="nb">int</span>  <span class="c1"># rank inside the group</span>
</span></span><span class="line"><span class="cl">    <span class="n">cpu_group</span><span class="p">:</span> <span class="n">ProcessGroup</span>  <span class="c1"># group for CPU communication</span>
</span></span><span class="line"><span class="cl">    <span class="n">device_group</span><span class="p">:</span> <span class="n">ProcessGroup</span>  <span class="c1"># group for device communication</span>
</span></span><span class="line"><span class="cl">    <span class="n">use_device_communicator</span><span class="p">:</span> <span class="nb">bool</span>  <span class="c1"># whether to use device communicator</span>
</span></span><span class="line"><span class="cl">    <span class="n">device_communicator</span><span class="p">:</span> <span class="n">DeviceCommunicatorBase</span>  <span class="c1"># device communicator</span>
</span></span><span class="line"><span class="cl">    <span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span>  <span class="c1"># shared memory broadcaster</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">group_ranks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">torch_distributed_backend</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Backend</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_device_communicator</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_message_queue_broadcaster</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">group_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">group_name</span> <span class="o">=</span> <span class="n">group_name</span> <span class="ow">or</span> <span class="s2">&#34;anonymous&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span> <span class="o">=</span> <span class="n">_get_unique_name</span><span class="p">(</span><span class="n">group_name</span><span class="p">)</span> <span class="c1">#group的名称</span>
</span></span><span class="line"><span class="cl">        <span class="n">_register_group</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="c1">#在_groups中登记，_groups是一个字典 unique_name-&gt;GroupCoordinator</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">local_rank</span> <span class="o">=</span> <span class="n">local_rank</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">ranks</span> <span class="ow">in</span> <span class="n">group_ranks</span><span class="p">:</span> <span class="c1">#定义所有的通信组</span>
</span></span><span class="line"><span class="cl">            <span class="n">device_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">torch_distributed_backend</span><span class="p">)</span> <span class="c1">#torch特性，所有rank都要new通信组，就算自己不在组内,解释是：保证每个rank都知道全局的通信情况，整个通信系统的状态每个rank要统一</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># a group with `gloo` backend, to allow direct coordination between</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># processes through the CPU.</span>
</span></span><span class="line"><span class="cl">            <span class="n">cpu_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s2">&#34;gloo&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">ranks</span> <span class="o">=</span> <span class="n">ranks</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ranks</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">rank_in_group</span> <span class="o">=</span> <span class="n">ranks</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="o">=</span> <span class="n">device_group</span>   <span class="c1">#每个rank确定自己的device_group</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="o">=</span> <span class="n">cpu_group</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_group</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">vllm.platforms</span> <span class="kn">import</span> <span class="n">current_platform</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># TODO: fix it for other platforms</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">current_platform</span><span class="o">.</span><span class="n">is_cuda_alike</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;cuda:</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_device_communicator</span> <span class="o">=</span> <span class="n">use_device_communicator</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">device_communicator</span><span class="p">:</span> <span class="n">DeviceCommunicatorBase</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">use_device_communicator</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">device_comm_cls</span> <span class="o">=</span> <span class="n">resolve_obj_by_qualname</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">current_platform</span><span class="o">.</span><span class="n">get_device_communicator_cls</span><span class="p">())</span> <span class="c1">#vllm自己搞的Communicator &#39;vllm.distributed.device_communicators.cuda_communicator.CudaCommunicator&#39;</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">device_communicator</span> <span class="o">=</span> <span class="n">device_comm_cls</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">cpu_group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">device_group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">unique_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_name</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span> <span class="c1">#每个rank实例化communicator,封装一层communicator便于实现定制化通信组内通信</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">vllm.distributed.device_communicators.shm_broadcast</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">MessageQueue</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MessageQueue</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">use_message_queue_broadcaster</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">mq_broadcaster</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_process_group</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">vllm.platforms</span> <span class="kn">import</span> <span class="n">current_platform</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_op_call</span> <span class="o">=</span> <span class="n">current_platform</span><span class="o">.</span><span class="n">is_cuda_alike</span><span class="p">()</span> <span class="c1">#是否是cuda场景，cuda场景有自己的优化</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">CudaCommunicator</span><span class="p">(</span><span class="n">DeviceCommunicatorBase</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">cpu_group</span><span class="p">:</span> <span class="n">ProcessGroup</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">device_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">unique_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&#34;&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">cpu_group</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">device_group</span><span class="p">,</span> <span class="n">unique_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s2">&#34;tp&#34;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unique_name</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># only tp uses custom allreduce</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="kn">from</span> <span class="nn">vllm.distributed.parallel_state</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">_ENABLE_CUSTOM_ALL_REDUCE</span>
</span></span><span class="line"><span class="cl">        <span class="n">use_pynccl</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_pynccl</span> <span class="o">=</span> <span class="n">use_pynccl</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_custom_allreduce</span> <span class="o">=</span> <span class="n">use_custom_allreduce</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># lazy import to avoid documentation build error</span>
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">vllm.distributed.device_communicators.custom_all_reduce</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">CustomAllreduce</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">vllm.distributed.device_communicators.pynccl</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">PyNcclCommunicator</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyNcclCommunicator</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">use_pynccl</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span> <span class="o">=</span> <span class="n">PyNcclCommunicator</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CustomAllreduce</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">use_custom_allreduce</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Initialize a custom fast all-reduce implementation.</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span> <span class="o">=</span> <span class="n">CustomAllreduce</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cpu_group</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">all_reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># always try custom allreduce first,</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and then pynccl.</span>
</span></span><span class="line"><span class="cl">        <span class="n">ca_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ca_comm</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">ca_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">disabled</span> <span class="ow">and</span> \
</span></span><span class="line"><span class="cl">            <span class="n">ca_comm</span><span class="o">.</span><span class="n">should_custom_ar</span><span class="p">(</span><span class="n">input_</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">ca_comm</span><span class="o">.</span><span class="n">custom_all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="n">out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">out</span>
</span></span><span class="line"><span class="cl">        <span class="n">pynccl_comm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pynccl_comm</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="n">pynccl_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">pynccl_comm</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># fall back to the default all-reduce using PyTorch.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># this usually happens during testing.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># when we run the model, allreduce only happens for the TP</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># group, where we always have either custom allreduce or pynccl.</span>
</span></span><span class="line"><span class="cl">            <span class="n">out</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_group</span><span class="p">)</span> <span class="c1">#实现还是用torch</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">out</span>
</span></span></code></pre></div><h4 id="实例化model_runner">实例化model_runner</h4>
<p>model_runner是Worker内的组件，是真正调用运行模型推理forward函数接口的类，会对input数据进行预处理。在实例化时会获取有关模型配置的信息，并预分配一些推理输入需要的空间，比如inputs_embeds，input_batch等。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">GPUModelRunner</span><span class="p">(</span><span class="n">LoRAModelRunnerMixin</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span> <span class="o">=</span> <span class="n">vllm_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">model_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cache_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">cache_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">lora_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">lora_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">load_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">load_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">scheduler_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">speculative_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">speculative_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_adapter_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">prompt_adapter_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">observability_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">observability_config</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span>
</span></span><span class="line"><span class="cl">        <span class="n">cache_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_config</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_config</span>
</span></span><span class="line"><span class="cl">        <span class="n">parallel_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span> <span class="o">=</span> <span class="n">is_pin_memory_available</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">dtype</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">cache_config</span><span class="o">.</span><span class="n">cache_dtype</span> <span class="o">==</span> <span class="s2">&#34;auto&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span> <span class="o">=</span> <span class="n">STR_DTYPE_TO_TORCH_DTYPE</span><span class="p">[</span>
</span></span><span class="line"><span class="cl">                <span class="n">cache_config</span><span class="o">.</span><span class="n">cache_dtype</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># NOTE(woosuk): sliding_window is None for models with interleaved</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># attention. Use interleaved_sliding_window instead.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">sliding_window</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get_sliding_window</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">interleaved_sliding_window</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">model_config</span><span class="o">.</span><span class="n">hf_text_config</span><span class="p">,</span> <span class="s2">&#34;interleaved_sliding_window&#34;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sliding_window</span>
</span></span><span class="line"><span class="cl">                            <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">interleaved_sliding_window</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">is_multimodal_model</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">is_multimodal_model</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="n">cache_config</span><span class="o">.</span><span class="n">block_size</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">max_model_len</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">max_model_len</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_blocks_per_req</span> <span class="o">=</span> <span class="n">cdiv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_model_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span> <span class="o">=</span> <span class="n">scheduler_config</span><span class="o">.</span><span class="n">max_num_batched_tokens</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_reqs</span> <span class="o">=</span> <span class="n">scheduler_config</span><span class="o">.</span><span class="n">max_num_seqs</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Model-related.  </span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_attn_layers</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get_num_layers_by_block_type</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">parallel_config</span><span class="p">,</span> <span class="n">LayerBlockType</span><span class="o">.</span><span class="n">attention</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_query_heads</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get_num_attention_heads</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">parallel_config</span><span class="p">)</span> <span class="c1">#存在tp，注意力头数量减半</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_kv_heads</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get_num_kv_heads</span><span class="p">(</span><span class="n">parallel_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get_head_size</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">get_hidden_size</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attn_backend</span> <span class="o">=</span> <span class="n">get_attn_backend</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">is_attention_free</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_mla</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">use_mla</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span><span class="c1">#attention后端 vllm.v1.attention.backends.flash_attn.FlashAttentionBackend</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_backend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">error_msg</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="sa">f</span><span class="s2">&#34;Error with get_att_backend: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">head_size</span><span class="si">=}</span><span class="s2">, &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">kv_cache_dtype</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">block_size</span><span class="si">=}</span><span class="s2">, &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">is_attention_free</span><span class="si">=}</span><span class="s2">, &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="sa">f</span><span class="s2">&#34;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">use_mla</span><span class="si">=}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;Non-Attention backend is not supported by V1 GPUModelRunner.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attn_metadata_builder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_backend</span><span class="o">.</span><span class="n">get_builder_cls</span><span class="p">()(</span>
</span></span><span class="line"><span class="cl">            <span class="n">weakref</span><span class="o">.</span><span class="n">proxy</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span><span class="c1">#通过attention后端生成一个attention元数据builder</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cascade_attn_enabled</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">disable_cascade_attn</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Multi-modal data support</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_registry</span> <span class="o">=</span> <span class="n">INPUT_REGISTRY</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">mm_registry</span> <span class="o">=</span> <span class="n">MULTIMODAL_REGISTRY</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">uses_mrope</span> <span class="o">=</span> <span class="n">model_config</span><span class="o">.</span><span class="n">uses_mrope</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">encoder_compute_budget</span><span class="p">,</span> <span class="n">encoder_cache_size</span> <span class="o">=</span> <span class="n">compute_encoder_budget</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">scheduler_config</span><span class="o">=</span><span class="n">scheduler_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">max_num_encoder_input_tokens</span> <span class="o">=</span> <span class="n">encoder_compute_budget</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_cache_size</span> <span class="o">=</span> <span class="n">encoder_cache_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Lazy initialization</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self.model: nn.Module  # Set after load_model</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">kv_caches</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># req_id -&gt; (input_id -&gt; encoder_output)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_cache</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Set up speculative decoding.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_spec_decode</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">speculative_config</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">use_spec_decode</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">speculative_config</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s2">&#34;ngram&#34;</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;Currently, only ngram spec decode is supported in V1.&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">is_last_rank</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">drafter</span> <span class="o">=</span> <span class="n">NgramProposer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Trigger Numba JIT compilation for N-gram proposer.</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># This usually takes less than 1 second.</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">drafter</span><span class="o">.</span><span class="n">propose</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">speculative_config</span><span class="o">.</span><span class="n">prompt_lookup_min</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">speculative_config</span><span class="o">.</span><span class="n">prompt_lookup_max</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                    <span class="bp">self</span><span class="o">.</span><span class="n">speculative_config</span><span class="o">.</span><span class="n">num_speculative_tokens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampler</span> <span class="o">=</span> <span class="n">RejectionSampler</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Request states.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">requests</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">CachedRequestState</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Persistent batch.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span> <span class="o">=</span> <span class="n">InputBatch</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_num_reqs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_reqs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_model_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_model_len</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">max_num_blocks_per_req</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_blocks_per_req</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">vocab_size</span><span class="o">=</span><span class="n">model_config</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span><span class="c1">#预分配inputbatch空间</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">use_cuda_graph</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">compilation_config</span><span class="o">.</span><span class="n">level</span>
</span></span><span class="line"><span class="cl">                               <span class="o">==</span> <span class="n">CompilationLevel</span><span class="o">.</span><span class="n">PIECEWISE</span>
</span></span><span class="line"><span class="cl">                               <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">enforce_eager</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># TODO(woosuk): Provide an option to tune the max cudagraph batch size.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># The convention is different.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self.cudagraph_batch_sizes sorts in ascending order.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># The batch sizes in the config are in descending order.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cudagraph_batch_sizes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="nb">reversed</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">compilation_config</span><span class="o">.</span><span class="n">cudagraph_capture_sizes</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Cache the device properties.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">device_properties</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_sms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_properties</span><span class="o">.</span><span class="n">multi_processor_count</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Persistent buffers for CUDA graphs.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                     <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                     <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="c1">#预分配空间</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                     <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                     <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="c1">#预分配空间</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># None in the first PP rank. The rest are set after load_model.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">IntermediateTensors</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Only relevant for models using M-RoPE (e.g, Qwen2-VL)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">uses_mrope</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># NOTE: `mrope_positions` is implemented with one additional dummy</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># position on purpose to make it non-contiguous so that it can work</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># with torch compile.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># See detailed explanation in https://github.com/vllm-project/vllm/pull/12128#discussion_r1926431923</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># NOTE: When M-RoPE is enabled, position ids are 3D regardless of</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># the modality of inputs. For text-only inputs, each dimension has</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># identical position IDs, making M-RoPE functionally equivalent to</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 1D-RoPE.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># See page 5 of https://arxiv.org/abs/2409.12191</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">mrope_positions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                               <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                               <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">mrope_positions_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">device</span><span class="o">=</span><span class="s2">&#34;cpu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1">#预分配空间</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># OPTIMIZATION: Cache the tensors rather than creating them every step.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">arange_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_reqs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                       <span class="bp">self</span><span class="o">.</span><span class="n">max_model_len</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                       <span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># NOTE(woosuk): These tensors are &#34;stateless&#34;, i.e., they are literally</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># a faster version of creating a new tensor every time. Thus, we should</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># not make any assumptions about the values in these tensors.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_ids_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">device</span><span class="o">=</span><span class="s2">&#34;cpu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">input_ids_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ids_cpu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">positions_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">device</span><span class="o">=</span><span class="s2">&#34;cpu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                         <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">positions_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">positions_cpu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">slot_mapping_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_tokens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="n">device</span><span class="o">=</span><span class="s2">&#34;cpu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">slot_mapping_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slot_mapping_cpu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">query_start_loc_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_reqs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                               <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                               <span class="n">device</span><span class="o">=</span><span class="s2">&#34;cpu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                               <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">query_start_loc_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_start_loc_cpu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">seq_lens_cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_num_reqs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">device</span><span class="o">=</span><span class="s2">&#34;cpu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">seq_lens_np</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_lens_cpu</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="worker加载参数">Worker加载参数</h3>
<p>对于self.worker.load_model()，依然需要wrapper的套壳，实际上执行worker类的load_model</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span> <span class="c1">#wrapper的函数</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Load model onto target device.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span> <span class="c1">#worker的函数</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">enable_sleep_mode</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">allocator</span> <span class="o">=</span> <span class="n">CuMemAllocator</span><span class="o">.</span><span class="n">get_instance</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="n">allocator</span><span class="o">.</span><span class="n">get_current_usage</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;Sleep mode can only be &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;used for one instance per process.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">context</span> <span class="o">=</span> <span class="n">allocator</span><span class="o">.</span><span class="n">use_memory_pool</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&#34;weights&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
</span></span><span class="line"><span class="cl">            <span class="n">context</span> <span class="o">=</span> <span class="n">nullcontext</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">context</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">model_runner</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span> <span class="c1">#model_runner进行模型加载</span>
</span></span></code></pre></div><p>最终是在model_runner加载参数</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;Starting to load model </span><span class="si">%s</span><span class="s2">...&#34;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">DeviceMemoryProfiler</span><span class="p">()</span> <span class="k">as</span> <span class="n">m</span><span class="p">:</span>  <span class="c1"># noqa: SIM117</span>
</span></span><span class="line"><span class="cl">        <span class="n">time_before_load</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="c1">#记录模型开始加载时间点</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">)</span> <span class="c1">#进行加载</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_config</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_lora_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="bp">self</span><span class="o">.</span><span class="n">scheduler_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="bp">self</span><span class="o">.</span><span class="n">lora_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                              <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">time_after_load</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="c1">#记录模型结束加载时间点</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">model_memory_usage</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">consumed_memory</span>
</span></span><span class="line"><span class="cl">    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;Model loading took </span><span class="si">%.4f</span><span class="s2"> GB and </span><span class="si">%.6f</span><span class="s2"> seconds&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">model_memory_usage</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">30</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">time_after_load</span> <span class="o">-</span> <span class="n">time_before_load</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">loader</span> <span class="o">=</span> <span class="n">get_model_loader</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">load_config</span><span class="p">)</span> <span class="c1">#实例化一个模型加载器</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">loader</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">)</span>  <span class="c1">#loader进行加载</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">device_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">device_config</span>
</span></span><span class="line"><span class="cl">    <span class="n">model_config</span> <span class="o">=</span> <span class="n">vllm_config</span><span class="o">.</span><span class="n">model_config</span>
</span></span><span class="line"><span class="cl">    <span class="n">target_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_config</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">set_default_torch_dtype</span><span class="p">(</span><span class="n">model_config</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">target_device</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">model</span> <span class="o">=</span> <span class="n">_initialize_model</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">)</span> <span class="c1">#实例化一个模型对象 比如Qwen2MoeForCausalLM</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">weights_to_load</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()}</span> <span class="c1">#记录需要加载的参数</span>
</span></span><span class="line"><span class="cl">        <span class="n">loaded_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_get_all_weights</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="n">model</span><span class="p">))</span> <span class="c1">#开始加载模型 这里其实就到了模型类自身的load_weights函数中</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">counter_after_loading_weights</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;Loading weights took </span><span class="si">%.2f</span><span class="s2"> seconds&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">counter_after_loading_weights</span> <span class="o">-</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">counter_before_loading_weights</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># We only enable strict check for non-quantized models</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># that have loaded weights tracking currently.</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">model_config</span><span class="o">.</span><span class="n">quantization</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">loaded_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">weights_not_loaded</span> <span class="o">=</span> <span class="n">weights_to_load</span> <span class="o">-</span> <span class="n">loaded_weights</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">weights_not_loaded</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="s2">&#34;Following weights were not initialized from &#34;</span>
</span></span><span class="line"><span class="cl">                    <span class="sa">f</span><span class="s2">&#34;checkpoint: </span><span class="si">{</span><span class="n">weights_not_loaded</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">_process_weights_after_loading</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                   <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span> <span class="c1">#这个函数是Qwen2MoeForCausalLM中的方法</span>
</span></span><span class="line"><span class="cl">        <span class="n">stacked_params_mapping</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># (param_name, shard_name, shard_id)</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="s2">&#34;qkv_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;q_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;q&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="s2">&#34;qkv_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;k_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;k&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="s2">&#34;qkv_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;v_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;v&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="s2">&#34;gate_up_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;gate_proj&#34;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="p">(</span><span class="s2">&#34;gate_up_proj&#34;</span><span class="p">,</span> <span class="s2">&#34;up_proj&#34;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Params for weights, fp8 weight scales, fp8 activation scales</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (param_name, weight_name, expert_id, shard_id)</span>
</span></span><span class="line"><span class="cl">        <span class="n">expert_params_mapping</span> <span class="o">=</span> <span class="n">FusedMoE</span><span class="o">.</span><span class="n">make_expert_params_mapping</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">ckpt_gate_proj_name</span><span class="o">=</span><span class="s2">&#34;gate_proj&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">ckpt_down_proj_name</span><span class="o">=</span><span class="s2">&#34;down_proj&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">ckpt_up_proj_name</span><span class="o">=</span><span class="s2">&#34;up_proj&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">num_experts</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_experts</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">params_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">loaded_params</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">loaded_weight</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="s2">&#34;rotary_emb.inv_freq&#34;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">shard_id</span><span class="p">)</span> <span class="ow">in</span> <span class="n">stacked_params_mapping</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Skip non-stacked layers and experts (experts handled below).</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">weight_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># We have mlp.experts[0].gate_proj in the checkpoint.</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Since we handle the experts below in expert_params_mapping,</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># we need to skip here BEFORE we update the name, otherwise</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># name will be updated to mlp.experts[0].gate_up_proj, which</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># will then be updated below in expert_params_mapping</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># for mlp.experts[0].gate_gate_up_proj, which breaks load.</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="s2">&#34;mlp.experts&#34;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Skip loading extra bias for GPTQ models.</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">((</span><span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;.bias&#34;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;_bias&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                        <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Skip layers on other devices.</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">is_pp_missing_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">continue</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">param</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="n">weight_loader</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">weight_loader</span>
</span></span><span class="line"><span class="cl">                <span class="n">weight_loader</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">loaded_weight</span><span class="p">,</span> <span class="n">shard_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">break</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">mapping</span> <span class="ow">in</span> <span class="n">expert_params_mapping</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">param_name</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">expert_id</span><span class="p">,</span> <span class="n">shard_id</span> <span class="o">=</span> <span class="n">mapping</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">weight_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                    <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="c1"># Skip layers on other devices.</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">is_pp_missing_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                    <span class="c1"># Skip loading extra bias for GPTQ models.</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="p">((</span><span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;.bias&#34;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;_bias&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                            <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                    <span class="n">param</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                    <span class="n">weight_loader</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">weight_loader</span>
</span></span><span class="line"><span class="cl">                    <span class="n">weight_loader</span><span class="p">(</span><span class="n">param</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">loaded_weight</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">name</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">shard_id</span><span class="o">=</span><span class="n">shard_id</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">expert_id</span><span class="o">=</span><span class="n">expert_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="k">break</span>
</span></span><span class="line"><span class="cl">                <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="c1"># Skip loading extra bias for GPTQ models.</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="p">((</span><span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;.bias&#34;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;_bias&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                            <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                    <span class="c1"># Skip layers on other devices.</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">is_pp_missing_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                    <span class="c1"># Remapping the name of FP8 kv-scale.</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&#34;kv_scale&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="n">remapped_kv_scale_name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                            <span class="s2">&#34;.kv_scale&#34;</span><span class="p">,</span> <span class="s2">&#34;.attn.kv_scale&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="k">if</span> <span class="n">remapped_kv_scale_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                            <span class="n">logger</span><span class="o">.</span><span class="n">warning_once</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                                <span class="s2">&#34;Found kv scale in the checkpoint &#34;</span>
</span></span><span class="line"><span class="cl">                                <span class="sa">f</span><span class="s2">&#34;(e.g. </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">), but not found the expected &#34;</span>
</span></span><span class="line"><span class="cl">                                <span class="sa">f</span><span class="s2">&#34;name in the model &#34;</span>
</span></span><span class="line"><span class="cl">                                <span class="sa">f</span><span class="s2">&#34;(e.g. </span><span class="si">{</span><span class="n">remapped_kv_scale_name</span><span class="si">}</span><span class="s2">). &#34;</span>
</span></span><span class="line"><span class="cl">                                <span class="s2">&#34;kv-scale is not loaded.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                            <span class="k">continue</span>
</span></span><span class="line"><span class="cl">                        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                            <span class="n">name</span> <span class="o">=</span> <span class="n">remapped_kv_scale_name</span>
</span></span><span class="line"><span class="cl">                    <span class="n">param</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                    <span class="n">weight_loader</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="s2">&#34;weight_loader&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="n">default_weight_loader</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">weight_loader</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">loaded_weight</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">loaded_params</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">loaded_params</span>
</span></span></code></pre></div><h2 id="worker的工作流">Worker的工作流</h2>
<p>Worker的工作流如下：</p>
<img src=".\image-20250417125428154.png" alt="image-20250417125428154" style="zoom:50%;" />
<p>vllm使用自己写的MessageQueue通信消息队列进行Executor和Worker间的<strong>任务请求发送</strong>和<strong>任务结果返回</strong>，为搞清楚Worker工作流，得先了解MessageQueue</p>
<h3 id="messagequeue">MessageQueue</h3>
<p>MessageQueue使用zmq通信库中的PUB-SUB模式（发布者-订阅者）进行消息传递，并且通信缓冲区使用自己写的ShmRingBuffer</p>
<p>zmq通信库中的PUB-SUB模式是一种一对多的通信模式，一个Publisher可以对应多个Subscriber。当PUB把消息传送到缓存区时，所有绑定了的SUB就可以接收到PUB发出的消息。</p>
<p>PUB-SUB模式非常适合多卡推理（比如：TP），因为Executor作为PUB发送推理任务请求后，所有的Worker作为SUB就可以获取同样的输入请求，进行并行推理（TP）。</p>
<p>MessageQueue的init函数如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MessageQueue</span><span class="p">:</span> <span class="c1">#PUB-SUB模式 PUB发送信息到ShmRingBuffer SUB从ShmRingBuffer中获取信息 一PUB对多SUB</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_reader</span><span class="p">,</span>  <span class="c1"># number of all readers</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_local_reader</span><span class="p">,</span>  <span class="c1"># number of local readers through shared memory</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_reader_ranks</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_chunk_bytes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_chunks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">connect_ip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">local_reader_ranks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_reader_ranks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_local_reader</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">local_reader_ranks</span><span class="p">)</span> <span class="o">==</span> <span class="n">n_local_reader</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">n_local_reader</span> <span class="o">=</span> <span class="n">n_local_reader</span>
</span></span><span class="line"><span class="cl">        <span class="n">n_remote_reader</span> <span class="o">=</span> <span class="n">n_reader</span> <span class="o">-</span> <span class="n">n_local_reader</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">n_remote_reader</span> <span class="o">=</span> <span class="n">n_remote_reader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">Context</span><span class="p">()</span> <span class="c1">#zmq上下文</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">n_local_reader</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># for local readers, we will:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 1. create a shared memory ring buffer to communicate small data</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 2. create a publish-subscribe socket to communicate large data</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">ShmRingBuffer</span><span class="p">(</span><span class="n">n_local_reader</span><span class="p">,</span> <span class="n">max_chunk_bytes</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">max_chunks</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># XPUB is very similar to PUB,</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># except that it can receive subscription messages</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># to confirm the number of subscribers</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">XPUB</span><span class="p">)</span> <span class="c1">#zmq的PUB-SUB模型 发布者订阅者模型</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># set the verbose option so that we can receive every subscription</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># message. otherwise, we will only receive the first subscription</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># see http://api.zeromq.org/3-3:zmq-setsockopt for more details</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span><span class="o">.</span><span class="n">setsockopt</span><span class="p">(</span><span class="n">XPUB_VERBOSE</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_subscribe_addr</span> <span class="o">=</span> <span class="n">get_open_zmq_ipc_path</span><span class="p">()</span> <span class="c1">#PUB-SUB进程间通信地址</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&#34;Binding to </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">local_subscribe_addr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">local_subscribe_addr</span><span class="p">)</span><span class="c1">#PUB绑定地址 Worker子进程作为SUB也会通过地址进行订阅</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">current_idx</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_subscribe_addr</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">current_idx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">remote_addr_ipv6</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">n_remote_reader</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># for remote readers, we will:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># create a publish-subscribe socket to communicate large data</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="ow">not</span> <span class="n">connect_ip</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">connect_ip</span> <span class="o">=</span> <span class="n">get_ip</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">XPUB</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span><span class="o">.</span><span class="n">setsockopt</span><span class="p">(</span><span class="n">XPUB_VERBOSE</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">remote_subscribe_port</span> <span class="o">=</span> <span class="n">get_open_port</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">is_valid_ipv6_address</span><span class="p">(</span><span class="n">connect_ip</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span><span class="o">.</span><span class="n">setsockopt</span><span class="p">(</span><span class="n">IPV6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">remote_addr_ipv6</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">                <span class="n">connect_ip</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;[</span><span class="si">{</span><span class="n">connect_ip</span><span class="si">}</span><span class="s2">]&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="n">socket_addr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;tcp://*:</span><span class="si">{</span><span class="n">remote_subscribe_port</span><span class="si">}</span><span class="s2">&#34;</span> 
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">socket_addr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">remote_subscribe_addr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&#34;tcp://</span><span class="si">{</span><span class="n">connect_ip</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">remote_subscribe_port</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">remote_subscribe_addr</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_is_writer</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1">#Executor作为PUB消息生产者</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_is_local_reader</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">local_reader_rank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># rank does not matter for remote readers</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_is_remote_reader</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">handle</span> <span class="o">=</span> <span class="n">Handle</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_reader_ranks</span><span class="o">=</span><span class="n">local_reader_ranks</span><span class="p">,</span><span class="c1">#本地rank序列</span>
</span></span><span class="line"><span class="cl">            <span class="n">buffer_handle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">buffer</span><span class="o">.</span><span class="n">handle</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_subscribe_addr</span><span class="o">=</span><span class="n">local_subscribe_addr</span><span class="p">,</span> <span class="c1">#PUB-SUB进程间通信地址</span>
</span></span><span class="line"><span class="cl">            <span class="n">remote_subscribe_addr</span><span class="o">=</span><span class="n">remote_subscribe_addr</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">remote_addr_ipv6</span><span class="o">=</span><span class="n">remote_addr_ipv6</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span> <span class="c1">#句柄</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&#34;vLLM message queue communication handle: </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">handle</span><span class="p">)</span>
</span></span></code></pre></div><p>Handle句柄包含了消息队列的核心内容，SUB可以根据句柄与PUB绑定，完成订阅</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">create_from_handle</span><span class="p">(</span><span class="n">handle</span><span class="p">:</span> <span class="n">Handle</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&#34;MessageQueue&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="n">MessageQueue</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">handle</span> <span class="o">=</span> <span class="n">handle</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_is_writer</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">Context</span><span class="p">()</span><span class="c1">#zmq上下文</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">handle</span><span class="o">.</span><span class="n">local_reader_ranks</span><span class="p">:</span><span class="c1">#是本地SUB rank</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="n">handle</span><span class="o">.</span><span class="n">buffer_handle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="n">ShmRingBuffer</span><span class="p">(</span><span class="o">*</span><span class="n">handle</span><span class="o">.</span><span class="n">buffer_handle</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">current_idx</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_reader_rank</span> <span class="o">=</span> <span class="n">handle</span><span class="o">.</span><span class="n">local_reader_ranks</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_is_local_reader</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1">#SUB是消费者</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_is_remote_reader</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">SUB</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span><span class="o">.</span><span class="n">setsockopt_string</span><span class="p">(</span><span class="n">SUBSCRIBE</span><span class="p">,</span> <span class="s2">&#34;&#34;</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">            <span class="n">socket_addr</span> <span class="o">=</span> <span class="n">handle</span><span class="o">.</span><span class="n">local_subscribe_addr</span> <span class="c1">#句柄中包含了消息队列通信地址，根据地址进行订阅</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&#34;Connecting to </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">socket_addr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">socket_addr</span><span class="p">)</span><span class="c1">#SUB绑定socket进行订阅</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">buffer</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">current_idx</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_reader_rank</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_is_local_reader</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_is_remote_reader</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">local_socket</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">SUB</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span><span class="o">.</span><span class="n">setsockopt_string</span><span class="p">(</span><span class="n">SUBSCRIBE</span><span class="p">,</span> <span class="s2">&#34;&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">handle</span><span class="o">.</span><span class="n">remote_addr_ipv6</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span><span class="o">.</span><span class="n">setsockopt</span><span class="p">(</span><span class="n">IPV6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">socket_addr</span> <span class="o">=</span> <span class="n">handle</span><span class="o">.</span><span class="n">remote_subscribe_addr</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&#34;Connecting to </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">socket_addr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">remote_socket</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">socket_addr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span>
</span></span></code></pre></div><h3 id="executor--worker--消息队列">Executor &lt;&ndash;&gt; Worker  消息队列</h3>
<p>Executor和Worker通过MessageQueue进行消息传输。</p>
<ol>
<li>Executor作为PUB，Worker作为SUB（1PUB-nSUB）： Executor作为PUB将任务请求发布出去，所有Worker作为SUB获取任务请求并执行任务。</li>
<li>Worker作为PUB，Executor作为SUB（1PUB-1SUB）： 所有Worker作为PUB将任务处理结果发布出去，Executor作为SUB获取n份任务处理结果并进一步合并。（TP中只有一份任务结果是有效的）</li>
</ol>
<h4 id="executor作为pubworker作为sub">Executor作为PUB，Worker作为SUB</h4>
<p>Executor中的init函数生成了MessageQueue，并将消息队列的句柄作为参数进行Worker的实例化</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MultiprocExecutor</span><span class="p">(</span><span class="n">Executor</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_init_executor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span> <span class="c1">#executor中有很多worker</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Call self.shutdown at exit to clean up</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and ensure workers will be terminated.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_finalizer</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># The child processes will send SIGUSR1 when unrecoverable</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># errors happen.</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">sigusr1_handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;MulitprocExecutor got fatal signal from worker processes, &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;shutting down. See stack trace above for root cause issue.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Propagate error up to parent process.</span>
</span></span><span class="line"><span class="cl">            <span class="n">parent_process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">parent_process</span><span class="o">.</span><span class="n">send_signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">,</span> <span class="n">sigusr1_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">tensor_parallel_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">tensor_parallel_size</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="n">tensor_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;world_size (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="s2">) must be equal to the &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;tensor_parallel_size (</span><span class="si">{</span><span class="n">tensor_parallel_size</span><span class="si">}</span><span class="s2">). &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;Pipeline parallelism is not yet implemented in v1&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Set multiprocessing envs that are common to V0 and V1</span>
</span></span><span class="line"><span class="cl">        <span class="n">set_multiprocessing_worker_envs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Multiprocessing-based executor does not support multi-node setting.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Since it only works for single node, we can use the loopback address</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 127.0.0.1 for communication.</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span> <span class="o">=</span> <span class="n">get_distributed_init_method</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;127.0.0.1&#34;</span><span class="p">,</span> <span class="n">get_open_port</span><span class="p">())</span>  <span class="c1">#找一个没人用的port</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize worker and set up message queues for SchedulerOutputs</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and ModelRunnerOutputs</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span> <span class="c1">#vllm自定义的一个消息队列 使用ZMQ的PUB-SUB模式 创建SUB个数为world_size的消息队列</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">export_handle</span><span class="p">()</span> <span class="c1">#handle句柄包含了SUB订阅所需的信息</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Create workers</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">WorkerProcHandle</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">):</span> <span class="c1">#对所有的tp创建一个worker进程</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="o">.</span><span class="n">make_worker_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                                    <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">scheduler_output_handle</span><span class="p">)</span>  <span class="c1">#消息队列句柄</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">worker</span><span class="p">)</span><span class="c1">#将worker进程的句柄（包括Worker创建的消息队列的句柄）加入workers中</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Ensure message queues are ready. Will deadlock if re-ordered</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Must be kept consistent with the WorkerProc      rpc_broadcast_mq是executor发给全体Worker的消息队列   worker_response_mq是Worker发送给executor的消息队列</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span> <span class="c1">#executor作为PUB 等待所有Worker作为SUB完成订阅</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span><span class="c1">#每个Worker都会创建一个消息队列</span>
</span></span><span class="line"><span class="cl">            <span class="n">w</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span><span class="c1">#executor作为SUB 等待作为PUB的Worker发送信息&#34;READY&#34;</span>
</span></span></code></pre></div><p>Worker实例化时会根据句柄，绑定通信路径进行订阅</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">WorkerProc</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Wrapper that runs one Worker in a separate process.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">READY_STR</span> <span class="o">=</span> <span class="s2">&#34;READY&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">input_shm_handle</span><span class="p">:</span> <span class="n">Handle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">ready_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
</span></span><span class="line"><span class="cl">        <span class="n">wrapper</span> <span class="o">=</span> <span class="n">WorkerWrapperBase</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">,</span> <span class="n">rpc_rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span> <span class="c1">#worker的一个封装管理器</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># TODO: move `init_worker` to executor level as a collective rpc call</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_kwargs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="p">{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_kwargs</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;vllm_config&#34;</span><span class="p">:</span> <span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;local_rank&#34;</span><span class="p">:</span> <span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;rank&#34;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed_init_method&#34;</span><span class="p">:</span> <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;is_driver_worker&#34;</span><span class="p">:</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">wrapper</span><span class="o">.</span><span class="n">init_worker</span><span class="p">(</span><span class="n">all_kwargs</span><span class="p">)</span> <span class="c1">#这里通过wrapper套壳进行worker真正的实例化，但仅仅实例化，还没加载参数，初始化分布式环境等</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span> <span class="o">=</span> <span class="n">wrapper</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">_add_prefix</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;VllmWorker rank=</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_add_prefix</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;VllmWorker rank=</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize MessageQueue for receiving SchedulerOutput</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_handle</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_shm_handle</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span> <span class="c1">#用消息队列句柄中的信息作为SUB 订阅PUB 隐式发送订阅消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initializes a message queue for sending the model output</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="c1">#创建SUB个数为1的消息队列，SUB就是executor</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">export_handle</span><span class="p">()</span><span class="c1">#Worker创建的消息队列的句柄</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Send Readiness signal to EngineCore process.</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">zmq_socket_ctx</span><span class="p">(</span><span class="n">ready_path</span><span class="p">,</span> <span class="n">zmq</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">PUSH</span><span class="p">)</span> <span class="k">as</span> <span class="n">ready_socket</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">payload</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">worker_response_mq_handle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span><span class="c1">#将Worker创建的消息队列的句柄转化为二进制数据</span>
</span></span><span class="line"><span class="cl">            <span class="n">ready_socket</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">READY_STR</span><span class="p">)</span><span class="c1">#用ready_path发送WorkerProc.READY_STR 就是字符串&#34;READY&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="n">ready_socket</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span><span class="c1">#发送句柄数据</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">init_device</span><span class="p">()</span>  <span class="c1">#worker与gpu绑定+初始化分布式环境，实例化多个通信组</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>   <span class="c1">#worker通过model_runner执行实例化模型对象，模型参数加载</span>
</span></span></code></pre></div><h4 id="worker作为pubexecutor作为sub">Worker作为PUB，Executor作为SUB</h4>
<p>每一个Worker实例化时都会生成一个消息队列，并将这个消息队列的句柄通过ready_path发送赋值给make_worker_process函数中的worker_response_mq_handle，进行订阅并封装成WorkerProcHandle后，返回给Executor，Executor此后根据WorkerProcHandle获取worker任务处理结果。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">WorkerProc</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Wrapper that runs one Worker in a separate process.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">READY_STR</span> <span class="o">=</span> <span class="s2">&#34;READY&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">input_shm_handle</span><span class="p">:</span> <span class="n">Handle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">ready_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">    <span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">rank</span>
</span></span><span class="line"><span class="cl">        <span class="n">wrapper</span> <span class="o">=</span> <span class="n">WorkerWrapperBase</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">=</span><span class="n">vllm_config</span><span class="p">,</span> <span class="n">rpc_rank</span><span class="o">=</span><span class="n">rank</span><span class="p">)</span> <span class="c1">#worker的一个封装管理器</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># TODO: move `init_worker` to executor level as a collective rpc call</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_kwargs</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">            <span class="p">{}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">all_kwargs</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;vllm_config&#34;</span><span class="p">:</span> <span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;local_rank&#34;</span><span class="p">:</span> <span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;rank&#34;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed_init_method&#34;</span><span class="p">:</span> <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;is_driver_worker&#34;</span><span class="p">:</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">wrapper</span><span class="o">.</span><span class="n">init_worker</span><span class="p">(</span><span class="n">all_kwargs</span><span class="p">)</span> <span class="c1">#这里通过wrapper套壳进行worker真正的实例化，但仅仅实例化，还没加载参数，初始化分布式环境等</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span> <span class="o">=</span> <span class="n">wrapper</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">pid</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">_add_prefix</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;VllmWorker rank=</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">_add_prefix</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&#34;VllmWorker rank=</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize MessageQueue for receiving SchedulerOutput</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_handle</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_shm_handle</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">rank</span><span class="p">)</span> <span class="c1">#用消息队列句柄中的信息作为SUB 订阅PUB 隐式发送订阅消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initializes a message queue for sending the model output</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="c1">#创建SUB个数为1的消息队列，SUB就是executor</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">export_handle</span><span class="p">()</span><span class="c1">#Worker创建的消息队列的句柄</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Send Readiness signal to EngineCore process.</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">zmq_socket_ctx</span><span class="p">(</span><span class="n">ready_path</span><span class="p">,</span> <span class="n">zmq</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">PUSH</span><span class="p">)</span> <span class="k">as</span> <span class="n">ready_socket</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">payload</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">worker_response_mq_handle</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span><span class="c1">#将Worker创建的消息队列的句柄转化为二进制数据</span>
</span></span><span class="line"><span class="cl">            <span class="n">ready_socket</span><span class="o">.</span><span class="n">send_string</span><span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">READY_STR</span><span class="p">)</span><span class="c1">#用ready_path发送WorkerProc.READY_STR 就是字符串&#34;READY&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="n">ready_socket</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span><span class="c1">#发送句柄数据</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">init_device</span><span class="p">()</span>  <span class="c1">#worker与gpu绑定+初始化分布式环境，实例化多个通信组</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>   <span class="c1">#worker通过model_runner执行实例化模型对象，模型参数加载</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">worker_main</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="c1">#**kwargs包括 &#34;input_shm_handle&#34; 消息队列句柄</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34; Worker initialization and execution loops.
</span></span></span><span class="line"><span class="cl"><span class="s2">        This runs a background process &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Signal handler used for graceful termination.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># SystemExit exception is only raised once to allow this and worker</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># processes to terminate without error</span>
</span></span><span class="line"><span class="cl">        <span class="n">shutdown_requested</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">signal_handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">nonlocal</span> <span class="n">shutdown_requested</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="ow">not</span> <span class="n">shutdown_requested</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">shutdown_requested</span> <span class="o">=</span> <span class="kc">True</span>
</span></span><span class="line"><span class="cl">                <span class="k">raise</span> <span class="ne">SystemExit</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Either SIGTERM or SIGINT will terminate the worker</span>
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGTERM</span><span class="p">,</span> <span class="n">signal_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">worker</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1">#开启worker进程</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Ensure message queues are ready. Will deadlock if re-ordered.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Must be kept consistent with the Executor</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span> <span class="c1">#worker作为SUB 等待作为PUB的executor作为PUB发来&#34;READY&#34;消息</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span><span class="c1">#worker作为PUB 等待所有作为SUB的订阅消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">worker</span><span class="o">.</span><span class="n">worker_busy_loop</span><span class="p">()</span> <span class="c1">#worker准备完毕，不断loop运行推理工作</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">SystemExit</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&#34;Worker interrupted.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># worker_busy_loop sends exceptions exceptons to Executor</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># for shutdown, but if there is an error in startup or an</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># error with IPC itself, we need to alert the parent.</span>
</span></span><span class="line"><span class="cl">            <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span><span class="o">.</span><span class="n">send_signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">finally</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Clean up once worker exits busy loop</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">worker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">worker</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">worker</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">                
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">make_worker_process</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">vllm_config</span><span class="p">:</span> <span class="n">VllmConfig</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">local_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">distributed_init_method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_shm_handle</span><span class="p">,</span>  <span class="c1">#消息队列句柄</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">WorkerProcHandle</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">get_mp_context</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ZMQ path for worker to send ready message and shm_broadcast handle</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># back to core process.</span>
</span></span><span class="line"><span class="cl">        <span class="n">ready_path</span> <span class="o">=</span> <span class="n">get_open_zmq_ipc_path</span><span class="p">()</span><span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">process_kwargs</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;vllm_config&#34;</span><span class="p">:</span> <span class="n">vllm_config</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;local_rank&#34;</span><span class="p">:</span> <span class="n">local_rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;rank&#34;</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;distributed_init_method&#34;</span><span class="p">:</span> <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;input_shm_handle&#34;</span><span class="p">:</span> <span class="n">input_shm_handle</span><span class="p">,</span> <span class="c1"># 消息队列句柄</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;ready_path&#34;</span><span class="p">:</span> <span class="n">ready_path</span><span class="p">,</span> <span class="c1">#zmq上下文定义的ready_path</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Run EngineCore busy loop in background process.</span>
</span></span><span class="line"><span class="cl">        <span class="n">proc</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">worker_main</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">kwargs</span><span class="o">=</span><span class="n">process_kwargs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">daemon</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#定义进程</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="n">proc</span><span class="o">.</span><span class="n">start</span><span class="p">()</span><span class="c1">#开启进程 执行worker_main函数</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        <span class="c1"># Wait for startup</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq_handle</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="o">.</span><span class="n">wait_for_startup</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">proc</span><span class="p">,</span> <span class="n">ready_path</span><span class="p">)</span><span class="c1">#等待Worker中通过ready_path发送&#34;READY&#34; 并且接收Worker创建的消息队列的句柄</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">worker_response_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="o">.</span><span class="n">create_from_handle</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker_response_mq_handle</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="c1">#订阅 作为Worker创建的消息队列的SUB成员</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">WorkerProcHandle</span><span class="p">(</span><span class="n">proc</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">ready_path</span><span class="p">,</span> <span class="n">worker_response_mq</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dataclass</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">WorkerProcHandle</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">proc</span><span class="p">:</span> <span class="n">BaseProcess</span>
</span></span><span class="line"><span class="cl">    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span>
</span></span><span class="line"><span class="cl">    <span class="n">ready_path</span><span class="p">:</span> <span class="nb">str</span>
</span></span><span class="line"><span class="cl">    <span class="n">worker_response_mq</span><span class="p">:</span> <span class="n">MessageQueue</span>  <span class="c1"># The worker process writes to this MQ       Worker创建的消息队列的SUB成员</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MultiprocExecutor</span><span class="p">(</span><span class="n">Executor</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_init_executor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span> <span class="c1">#executor中有很多worker</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Call self.shutdown at exit to clean up</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and ensure workers will be terminated.</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_finalizer</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># The child processes will send SIGUSR1 when unrecoverable</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># errors happen.</span>
</span></span><span class="line"><span class="cl">        <span class="k">def</span> <span class="nf">sigusr1_handler</span><span class="p">(</span><span class="n">signum</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">logger</span><span class="o">.</span><span class="n">fatal</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;MulitprocExecutor got fatal signal from worker processes, &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;shutting down. See stack trace above for root cause issue.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Propagate error up to parent process.</span>
</span></span><span class="line"><span class="cl">            <span class="n">parent_process</span> <span class="o">=</span> <span class="n">psutil</span><span class="o">.</span><span class="n">Process</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">parent_process</span><span class="o">.</span><span class="n">send_signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">signal</span><span class="o">.</span><span class="n">signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGUSR1</span><span class="p">,</span> <span class="n">sigusr1_handler</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">world_size</span>
</span></span><span class="line"><span class="cl">        <span class="n">tensor_parallel_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="o">.</span><span class="n">tensor_parallel_size</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="n">tensor_parallel_size</span><span class="p">,</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;world_size (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="si">}</span><span class="s2">) must be equal to the &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;tensor_parallel_size (</span><span class="si">{</span><span class="n">tensor_parallel_size</span><span class="si">}</span><span class="s2">). &#34;</span>
</span></span><span class="line"><span class="cl">            <span class="sa">f</span><span class="s2">&#34;Pipeline parallelism is not yet implemented in v1&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Set multiprocessing envs that are common to V0 and V1</span>
</span></span><span class="line"><span class="cl">        <span class="n">set_multiprocessing_worker_envs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parallel_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Multiprocessing-based executor does not support multi-node setting.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Since it only works for single node, we can use the loopback address</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 127.0.0.1 for communication.</span>
</span></span><span class="line"><span class="cl">        <span class="n">distributed_init_method</span> <span class="o">=</span> <span class="n">get_distributed_init_method</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="s2">&#34;127.0.0.1&#34;</span><span class="p">,</span> <span class="n">get_open_port</span><span class="p">())</span>  <span class="c1">#找一个没人用的port</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Initialize worker and set up message queues for SchedulerOutputs</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and ModelRunnerOutputs</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span> <span class="o">=</span> <span class="n">MessageQueue</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span> <span class="c1">#vllm自定义的一个消息队列 使用ZMQ的PUB-SUB模式 创建SUB个数为world_size的消息队列</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output_handle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">export_handle</span><span class="p">()</span> <span class="c1">#handle句柄包含了SUB订阅所需的信息</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Create workers</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">WorkerProcHandle</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">):</span> <span class="c1">#对所有的tp创建一个worker进程</span>
</span></span><span class="line"><span class="cl">            <span class="n">worker</span> <span class="o">=</span> <span class="n">WorkerProc</span><span class="o">.</span><span class="n">make_worker_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                                                    <span class="n">rank</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">distributed_init_method</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                    <span class="n">scheduler_output_handle</span><span class="p">)</span>  <span class="c1">#消息队列句柄</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">worker</span><span class="p">)</span><span class="c1">#将worker进程的句柄（包括Worker创建的消息队列的句柄）加入workers中</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Ensure message queues are ready. Will deadlock if re-ordered</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Must be kept consistent with the WorkerProc      rpc_broadcast_mq是executor发给全体Worker的消息队列   worker_response_mq是Worker发送给executor的消息队列</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span> <span class="c1">#executor作为PUB 等待所有Worker作为SUB完成订阅</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span><span class="c1">#每个Worker都会创建一个消息队列</span>
</span></span><span class="line"><span class="cl">            <span class="n">w</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">wait_until_ready</span><span class="p">()</span><span class="c1">#executor作为SUB 等待作为PUB的Worker发送信息&#34;READY&#34;</span>
</span></span></code></pre></div><h3 id="工作流程">工作流程</h3>
<h4 id="worker_busy_loop">worker_busy_loop</h4>
<p>Worker进行完实例化后，会和EngineCore一样进入loop，不断 等待任务请求&ndash;处理&ndash;输出任务结果</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">worker_busy_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Main busy loop for Multiprocessing Workers&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">method</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">dequeue</span><span class="p">()</span> <span class="c1">#接收来自executor的任务消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cloudpickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">method</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">output</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1">#对任务进行处理</span>
</span></span><span class="line"><span class="cl">            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Notes have been introduced in python 3.11</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="s2">&#34;add_note&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">e</span><span class="o">.</span><span class="n">add_note</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">ResponseStatus</span><span class="o">.</span><span class="n">FAILURE</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="s2">&#34;WorkerProc hit an exception: </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;my rank is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="si">}</span><span class="s2">, my output is </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">ResponseStatus</span><span class="o">.</span><span class="n">SUCCESS</span><span class="p">,</span> <span class="n">output</span><span class="p">))</span><span class="c1">#处理完的任务结果 通过worker_response_mq发送个executor</span>
</span></span></code></pre></div><h4 id="enginecore-executor-worker-model_runner-forward">EngineCore-&gt;Executor-&gt;Worker-&gt;model_runner-&gt;forward</h4>
<p>模拟EngineCore-&gt;Executor-&gt;Worker-&gt;model_runner-&gt;forward流程</p>
<p>当EngineCore的input_queue有来自EngineCoreClient的请求时，会进行step_fn</p>
<p>在step_fn中会先让Scheduler生成调度安排，然后让Executor以scheduler_output为参数执行函数execute_model</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">run_busy_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Core busy loop of the EngineCore.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">step_fn</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step</span>
</span></span><span class="line"><span class="cl">                   <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_queue</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_with_batch_queue</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Loop until process is sent a SIGINT or SIGTERM</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 1) Poll the input queue until there is work to do.</span>
</span></span><span class="line"><span class="cl">            <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">has_requests</span><span class="p">():</span>  <span class="c1">#Scheduler中没需要处理的请求就一直循环，直到有请求</span>
</span></span><span class="line"><span class="cl">                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&#34;EngineCore busy loop waiting.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">req</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>  <span class="c1">#如果没有请求，这里会进行阻塞，从而减少资源浪费</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">_handle_client_request</span><span class="p">(</span><span class="o">*</span><span class="n">req</span><span class="p">)</span>  <span class="c1">#处理EngineCoreClient发送的请求，Scheduler将请求加入队列</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># 2) Handle any new client requests.  现在Scheduler中有请求了</span>
</span></span><span class="line"><span class="cl">            <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_queue</span><span class="o">.</span><span class="n">empty</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                <span class="n">req</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_queue</span><span class="o">.</span><span class="n">get_nowait</span><span class="p">()</span>  <span class="c1">#这里已经有请求了，所以使用的非阻塞的get_nowait()快速处理这些新请求，1和2分开的目的是减少资源浪费</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">_handle_client_request</span><span class="p">(</span><span class="o">*</span><span class="n">req</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># 3) Step the engine core.</span>
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_fn</span><span class="p">()</span>  <span class="c1">#进行一次推理，让Scheduler生成调度安排，利用调度安排进行推理执行，更新结果，返回推理output</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># 4) Put EngineCoreOutputs into the output queue.</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">output_queue</span><span class="o">.</span><span class="n">put_nowait</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">EngineCoreOutputs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Schedule, execute, and make output.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Check for any requests remaining in the scheduler - unfinished,</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># or finished and not yet removed from the batch.</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">has_requests</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">EngineCoreOutputs</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">outputs</span><span class="o">=</span><span class="p">[],</span>
</span></span><span class="line"><span class="cl">                <span class="n">scheduler_stats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">make_stats</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">schedule</span><span class="p">()</span> <span class="c1">#让Scheduler生成调度安排</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_executor</span><span class="o">.</span><span class="n">execute_model</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">)</span><span class="c1">#executor根据调度安排，给worker发布任务请求，并获取输出</span>
</span></span><span class="line"><span class="cl">        <span class="n">engine_core_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">update_from_output</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">scheduler_output</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>  <span class="c1"># type: ignore  #更新结果</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">engine_core_outputs</span>
</span></span></code></pre></div><p>Executor中执行execute_model(scheduler_output)实际是把scheduler_output作为任务请求通过rpc_broadcast_mq发送给Worker</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">execute_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">ModelRunnerOutput</span><span class="p">,</span> <span class="n">Future</span><span class="p">[</span><span class="n">ModelRunnerOutput</span><span class="p">]]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collective_rpc</span><span class="p">(</span><span class="s2">&#34;execute_model&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                     <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">,</span> <span class="p">))</span>  <span class="c1">#执行模型，进行一次推理</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">collective_rpc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                       <span class="n">method</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                       <span class="n">timeout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                       <span class="n">args</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="p">(),</span>
</span></span><span class="line"><span class="cl">                       <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># NOTE: If the args are heterogeneous, then we pack them into a list,</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># and unpack them in the method of every worker, because every worker</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># knows their own rank.</span>
</span></span><span class="line"><span class="cl">        <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">send_method</span> <span class="o">=</span> <span class="n">method</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">send_method</span> <span class="o">=</span> <span class="n">cloudpickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">method</span><span class="p">,</span> <span class="n">protocol</span><span class="o">=</span><span class="n">pickle</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">enqueue</span><span class="p">((</span><span class="n">send_method</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">))</span><span class="c1">#executor发布任务给worker</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">responses</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">workers</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">dequeue_timeout</span> <span class="o">=</span> <span class="n">timeout</span> <span class="o">-</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
</span></span><span class="line"><span class="cl">                                             <span class="p">)</span> <span class="k">if</span> <span class="n">timeout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">                <span class="n">status</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">dequeue</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">timeout</span><span class="o">=</span><span class="n">dequeue_timeout</span><span class="p">)</span><span class="c1">#获取从worker输出的结果</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">status</span> <span class="o">!=</span> <span class="n">WorkerProc</span><span class="o">.</span><span class="n">ResponseStatus</span><span class="o">.</span><span class="n">SUCCESS</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                        <span class="k">raise</span> <span class="n">result</span>
</span></span><span class="line"><span class="cl">                    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&#34;Worker failed&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">responses</span><span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">responses</span>
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">TimeoutError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">TimeoutError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;RPC call to </span><span class="si">{</span><span class="n">method</span><span class="si">}</span><span class="s2"> timed out.&#34;</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Re-raise any other exceptions</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="n">e</span>
</span></span></code></pre></div><p>Worker一直在loop，当收到Executor作为PUB发送的任务后，就会进行处理</p>
<p>当然这里的任务包括很多（get_kv_cache_specs/determine_available_memory/compile_or_warm_up_model），这里考虑&quot;execute_model&quot;</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">worker_busy_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Main busy loop for Multiprocessing Workers&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">method</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rpc_broadcast_mq</span><span class="o">.</span><span class="n">dequeue</span><span class="p">()</span> <span class="c1">#接收来自executor的任务消息</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="p">,</span> <span class="n">method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">func</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">cloudpickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">method</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">worker</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">output</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="c1">#对任务进行处理</span>
</span></span><span class="line"><span class="cl">            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Notes have been introduced in python 3.11</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="s2">&#34;add_note&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                    <span class="n">e</span><span class="o">.</span><span class="n">add_note</span><span class="p">(</span><span class="n">traceback</span><span class="o">.</span><span class="n">format_exc</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">ResponseStatus</span><span class="o">.</span><span class="n">FAILURE</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                <span class="n">logger</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="s2">&#34;WorkerProc hit an exception: </span><span class="si">%s</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">exc_info</span><span class="o">=</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;my rank is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="si">}</span><span class="s2">, my output is </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">worker_response_mq</span><span class="o">.</span><span class="n">enqueue</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="p">(</span><span class="n">WorkerProc</span><span class="o">.</span><span class="n">ResponseStatus</span><span class="o">.</span><span class="n">SUCCESS</span><span class="p">,</span> <span class="n">output</span><span class="p">))</span><span class="c1">#处理完的任务结果 通过worker_response_mq发送给executor</span>
</span></span><span class="line"><span class="cl">            
</span></span><span class="line"><span class="cl">    <span class="nd">@torch.inference_mode</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">execute_model</span><span class="p">(</span> <span class="c1">#Worker内的方法</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output</span><span class="p">:</span> <span class="s2">&#34;SchedulerOutput&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelRunnerOutput</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_runner</span><span class="o">.</span><span class="n">execute_model</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">)</span>  <span class="c1">#进行一次推理每个请求获取一个结果token</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_driver_worker</span> <span class="k">else</span> <span class="kc">None</span>
</span></span></code></pre></div><p>Worker最后执行推理是把任务交给了model_runner，self.model_runner.execute_model(scheduler_output)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="nd">@torch.inference_mode</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">execute_model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">scheduler_output</span><span class="p">:</span> <span class="s2">&#34;SchedulerOutput&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">intermediate_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">IntermediateTensors</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">ModelRunnerOutput</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_update_states</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">scheduler_output</span><span class="o">.</span><span class="n">total_num_scheduled_tokens</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Return empty ModelRunnerOuptut if there&#39;s no work to do.</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">EMPTY_MODEL_RUNNER_OUTPUT</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_multimodal_model</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Run the multimodal encoder if any.</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_execute_encoder</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gather_encoder_outputs</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">encoder_outputs</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Prepare the decoder inputs.</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn_metadata</span><span class="p">,</span> <span class="n">logits_indices</span><span class="p">,</span> <span class="n">spec_decode_metadata</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_inputs</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">))</span><span class="c1">#准备输入数据</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_scheduled_tokens</span> <span class="o">=</span> <span class="n">scheduler_output</span><span class="o">.</span><span class="n">total_num_scheduled_tokens</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">use_cuda_graph</span>
</span></span><span class="line"><span class="cl">                <span class="ow">and</span> <span class="n">num_scheduled_tokens</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cudagraph_batch_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Use piecewise CUDA graphs.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Add padding to the batch size.</span>
</span></span><span class="line"><span class="cl">            <span class="n">num_input_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="o">.</span><span class="n">pad_for_cudagraph</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">num_scheduled_tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Eager mode.</span>
</span></span><span class="line"><span class="cl">            <span class="n">num_input_tokens</span> <span class="o">=</span> <span class="n">num_scheduled_tokens</span>
</span></span><span class="line"><span class="cl">        <span class="n">attn_metadata</span><span class="o">.</span><span class="n">num_input_tokens</span> <span class="o">=</span> <span class="n">num_input_tokens</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_multimodal_model</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># NOTE(woosuk): To unify token ids and soft tokens (vision</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># embeddings), we always use embeddings (rather than token ids)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># as input to the multimodal model, even when the input is text.</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[:</span><span class="n">num_scheduled_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">encoder_outputs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">input_ids</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># TODO(woosuk): Avoid the copy. Optimize.</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">inputs_embeds</span><span class="p">[:</span><span class="n">num_scheduled_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs_embeds</span><span class="p">[:</span><span class="n">num_input_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_ids</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># For text-only models, we use token ids as input.</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># While it is possible to use embeddings as input just like the</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># multimodal models, it is not desirable for performance since</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># then the embedding layer is not included in the CUDA graph.</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[:</span><span class="n">num_input_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">uses_mrope</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mrope_positions</span><span class="p">[:,</span> <span class="p">:</span><span class="n">num_input_tokens</span><span class="p">]</span><span class="c1">#位置向量</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">positions</span><span class="p">[:</span><span class="n">num_input_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">is_first_rank</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">intermediate_tensors</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="n">intermediate_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">intermediate_tensors</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_tensors</span><span class="p">[</span><span class="n">k</span><span class="p">][:</span><span class="n">num_input_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                    <span class="n">v</span><span class="p">[:</span><span class="n">num_input_tokens</span><span class="p">],</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">intermediate_tensors</span> <span class="o">=</span> <span class="n">IntermediateTensors</span><span class="p">({</span>
</span></span><span class="line"><span class="cl">                <span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[:</span><span class="n">num_input_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_tensors</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="p">})</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Run the decoder.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Use persistent buffers for CUDA graphs.</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">set_forward_context</span><span class="p">(</span><span class="n">attn_metadata</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">intermediate_tensors</span><span class="o">=</span><span class="n">intermediate_tensors</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>  
</span></span><span class="line"><span class="cl">            <span class="p">)</span>                     <span class="c1">#执行forward</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="n">get_pp_group</span><span class="p">()</span><span class="o">.</span><span class="n">is_last_rank</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># For mid-pipeline stages, return the hidden states.</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">hidden_states</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:</span><span class="n">num_scheduled_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">sample_hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[</span><span class="n">logits_indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">compute_logits</span><span class="p">(</span><span class="n">sample_hidden_states</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Apply structured output bitmasks if present</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">scheduler_output</span><span class="o">.</span><span class="n">grammar_bitmask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">apply_grammar_bitmask</span><span class="p">(</span><span class="n">scheduler_output</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Sample the next token and get logprobs if needed.</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampling_metadata</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span><span class="o">.</span><span class="n">sampling_metadata</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">spec_decode_metadata</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">sampler_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">sampling_metadata</span><span class="o">=</span><span class="n">sampling_metadata</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># When indexing with a tensor (bonus_logits_indices), PyTorch</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># creates a new tensor with separate storage from the original</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># logits tensor. This means any in-place operations on bonus_logits</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># won&#39;t affect the original logits tensor.</span>
</span></span><span class="line"><span class="cl">            <span class="n">bonus_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">spec_decode_metadata</span><span class="o">.</span><span class="n">bonus_logits_indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">sampler_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">logits</span><span class="o">=</span><span class="n">bonus_logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">sampling_metadata</span><span class="o">=</span><span class="n">sampling_metadata</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">bonus_token_ids</span> <span class="o">=</span> <span class="n">sampler_output</span><span class="o">.</span><span class="n">sampled_token_ids</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># Just like `bonus_logits`, `target_logits` is a new tensor with</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># separate storage from the original `logits` tensor. Therefore,</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># it is safe to update `target_logits` in place.</span>
</span></span><span class="line"><span class="cl">            <span class="n">target_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">spec_decode_metadata</span><span class="o">.</span><span class="n">target_logits_indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">output_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampler</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">spec_decode_metadata</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="kc">None</span><span class="p">,</span>  <span class="c1"># draft_probs</span>
</span></span><span class="line"><span class="cl">                <span class="n">target_logits</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">bonus_token_ids</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">sampling_metadata</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">sampler_output</span><span class="o">.</span><span class="n">sampled_token_ids</span> <span class="o">=</span> <span class="n">output_token_ids</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># TODO(woosuk): The following loop can be slow since it iterates over</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># the requests one by one. Optimize.</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">generator</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span><span class="o">.</span><span class="n">generators</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="n">req_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span><span class="o">.</span><span class="n">req_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">req_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">requests</span><span class="p">[</span><span class="n">req_id</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">seq_len</span> <span class="o">=</span> <span class="p">(</span><span class="n">req_state</span><span class="o">.</span><span class="n">num_computed_tokens</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                       <span class="n">scheduler_output</span><span class="o">.</span><span class="n">num_scheduled_tokens</span><span class="p">[</span><span class="n">req_id</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&lt;</span> <span class="n">req_state</span><span class="o">.</span><span class="n">num_tokens</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Ignore the sampled token for partial prefills.</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># Rewind the generator state as if the token was not sampled.</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># This relies on cuda-specific torch-internal impl details</span>
</span></span><span class="line"><span class="cl">                <span class="n">generator</span><span class="o">.</span><span class="n">set_offset</span><span class="p">(</span><span class="n">generator</span><span class="o">.</span><span class="n">get_offset</span><span class="p">()</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># NOTE: GPU -&gt; CPU Sync happens here.</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># Move as many CPU operations as possible before this sync point.</span>
</span></span><span class="line"><span class="cl">        <span class="n">logprobs_tensors</span> <span class="o">=</span> <span class="n">sampler_output</span><span class="o">.</span><span class="n">logprobs_tensors</span>
</span></span><span class="line"><span class="cl">        <span class="n">logprobs_lists</span> <span class="o">=</span> <span class="n">logprobs_tensors</span><span class="o">.</span><span class="n">tolists</span><span class="p">()</span> \
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">logprobs_tensors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Compute prompt logprobs if needed.</span>
</span></span><span class="line"><span class="cl">        <span class="n">prompt_logprobs_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_prompt_logprobs_dict</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">hidden_states</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">scheduler_output</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># Get the valid generated tokens.</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampled_token_ids</span> <span class="o">=</span> <span class="n">sampler_output</span><span class="o">.</span><span class="n">sampled_token_ids</span>
</span></span><span class="line"><span class="cl">        <span class="n">max_gen_len</span> <span class="o">=</span> <span class="n">sampled_token_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">max_gen_len</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># No spec decode tokens.</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_sampled_token_ids</span> <span class="o">=</span> <span class="n">sampled_token_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># Includes spec decode tokens.</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_sampled_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rejection_sampler</span><span class="o">.</span><span class="n">parse_output</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">sampled_token_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_spec_decode</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">spec_token_ids</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">spec_token_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_draft_token_ids</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">valid_sampled_token_ids</span><span class="p">,</span> <span class="n">sampling_metadata</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ModelRunnerOutput</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">req_ids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span><span class="o">.</span><span class="n">req_ids</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">req_id_to_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">input_batch</span><span class="o">.</span><span class="n">req_id_to_index</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">sampled_token_ids</span><span class="o">=</span><span class="n">valid_sampled_token_ids</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">spec_token_ids</span><span class="o">=</span><span class="n">spec_token_ids</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">logprobs</span><span class="o">=</span><span class="n">logprobs_lists</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">prompt_logprobs_dict</span><span class="o">=</span><span class="n">prompt_logprobs_dict</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span> <span class="c1">#execute_model的返回类型是ModelRunnerOutput</span>
</span></span></code></pre></div><p>model runner最终执行forward</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">with</span> <span class="n">set_forward_context</span><span class="p">(</span><span class="n">attn_metadata</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vllm_config</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">intermediate_tensors</span><span class="o">=</span><span class="n">intermediate_tensors</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>  
</span></span><span class="line"><span class="cl">            <span class="p">)</span>                     <span class="c1">#执行forward</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">positions</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">intermediate_tensors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">IntermediateTensors</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">IntermediateTensors</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">intermediate_tensors</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">inputs_embeds</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">hidden_states</span>
</span></span></code></pre></div>
            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;

    <div class="footer_social-icons">
<a href="https://github.com/theflash010" target="_blank" rel="noopener noreferrer me"
    title="Github">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
</a>
<a href="https://space.bilibili.com/106734387?spm_id_from=333.1007.0.0" target="_blank" rel="noopener noreferrer me"
    title="Bilibili">
    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" xmlns="http://www.w3.org/2000/svg">
    <rect x="1.3333" y="6" width="21.333" height="15.333" rx="4" ry="4"/>
    <path d="m8 12.4v1.2"/>
    <path d="m16 12.4v1.2"/>
    <path d="m5.8853 2.6667 2.6667 2.6667"/>
    <path d="m18.115 2.6667-2.6667 2.6667"/>
</svg>
</a>
<a href="/index.xml" target="_blank" rel="noopener noreferrer me"
    title="Rss">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 11a9 9 0 0 1 9 9" />
    <path d="M4 4a16 16 0 0 1 16 16" />
    <circle cx="5" cy="19" r="1" />
</svg>
</a>
</div>
    <small class="footer_copyright">
        © 2025 Nan Z.
        Powered by <a href="https://github.com/hugo-sid/hugo-blog-awesome" target="_blank" rel="noopener">Hugo blog awesome</a>.
    </small>
</footer><a href="#" title="Go to top" id="totop">
    <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" fill="currentColor" stroke="currentColor" viewBox="0 96 960 960">
    <path d="M283 704.739 234.261 656 480 410.261 725.739 656 677 704.739l-197-197-197 197Z"/>
</svg>

</a>


    




    
    
        
    

    
    
        
    



    
    <script src="https://theflash010.github.io/js/main.min.35f435a5d8eac613c52daa28d8af544a4512337d3e95236e4a4978417b8dcb2f.js" integrity="sha256-NfQ1pdjqxhPFLaoo2K9USkUSM30&#43;lSNuSkl4QXuNyy8="></script>

    

</body>
</html>
