<!DOCTYPE html>
<html lang="en-gb"><head><meta charset="utf-8">
<meta http-equiv="content-type" content="text/html">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title itemprop="name">LLM Scheduling | NAN blog</title>
<meta property="og:title" content="LLM Scheduling | NAN blog" />
<meta name="twitter:title" content="LLM Scheduling | NAN blog" />
<meta itemprop="name" content="LLM Scheduling | NAN blog" />
<meta name="application-name" content="LLM Scheduling | NAN blog" />
<meta property="og:site_name" content="NAN blog" />

<meta name="description" content="Record of Learning Journey">
<meta itemprop="description" content="Record of Learning Journey" />
<meta property="og:description" content="Record of Learning Journey" />
<meta name="twitter:description" content="Record of Learning Journey" />

<meta property="og:locale" content="en-gb" />
<meta name="language" content="en-gb" />

  <link rel="alternate" hreflang="en-gb" href="https://theflash010.github.io/posts/llm-scheduling/" title="English" />





    
    
    

    <meta property="og:type" content="article" />
    <meta property="og:article:published_time" content=2025-03-27T14:32:49&#43;0800 />
    <meta property="article:published_time" content=2025-03-27T14:32:49&#43;0800 />
    <meta property="og:url" content="https://theflash010.github.io/posts/llm-scheduling/" />

    
    <meta property="og:article:author" content="Nan Z" />
    <meta property="article:author" content="Nan Z" />
    <meta name="author" content="Nan Z" />
    
    

    

    <script defer type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "Article",
        "headline": "LLM Scheduling",
        "author": {
        "@type": "Person",
        "name": ""
        },
        "datePublished": "2025-03-27",
        "description": "",
        "wordCount":  33 ,
        "mainEntityOfPage": "True",
        "dateModified": "2025-03-27",
        "image": {
        "@type": "imageObject",
        "url": ""
        },
        "publisher": {
        "@type": "Organization",
        "name": "NAN blog"
        }
    }
    </script>


<meta name="generator" content="Hugo 0.145.0">

    
    <meta property="og:url" content="https://theflash010.github.io/posts/llm-scheduling/">
  <meta property="og:site_name" content="NAN blog">
  <meta property="og:title" content="LLM Scheduling">
  <meta property="og:description" content="有关大模型任务调度的讨论 大模型具有一些内在的特性，导致在大模型任务调度方面会有一些新的挑战。
冷启动问题 大模型的特点之一是参数规模非常大，常见的175B,670B等等。
当系统的请求量变化时，需要针对集群开发新的调度策略，其中就包括改变集群中不同模型副本的数量，也就是进行扩缩容操作。然而由于大模型的参数规模大，导致在gpu上加载新模型的开销非常大，甚至对于大多数大模型来说，单张gpu无法达到推理的显存需求，需要在好几张gpu上加载大模型，进一步导致大模型的冷启动问题。不同参数规模的大模型加载开销不同，但基本都要超过10分钟的开销。
针对大模型的冷启动问题常用的解决思路如下
预测流派 调度的根本原因在于系统请求量的变化，预测流派使用EWMA，ARIMA等方法粗粒度的提前预测下一时段的系统请求量，并提前计算好新的调度策略。
粗粒度是按照小时来作为时间段的单位，预测下一时段（几个小时）的请求量是多少，然后在下一个时段中慢慢进行模型的加载（因为相比于小时，10min还是比较短的时间）。由于是提前预测好，并不是系统突然的请求量burst，所以可以消除冷启动带来的影响（等到请求量增大时，已经提前加载好了大模型）
预测流派需要对系统请求量的变化有相对准确的预测，如果不准确会导致资源的浪费（多加载了大模型）/SLO 冲突（少加载了大模型）
相关文献《Serving Models, Fast and Slow:Optimizing Heterogeneous LLM Inferencing Workloads at Scale》
这个paper中还详细讨论了在下一个时段中慢慢进行模型加载的策略
Naive方法：在得出新的调度策略后，直接进行改变
Instance Utilization (LT-U)方法：考虑模型实例的使用率，当使用率增大超过某一个阈值时按照新的调度策略逐渐加载新的模型副本，但是不可以超过调度策略规定的值，相反，当使用率减少低于某一个阈值时按照新的调度策略逐渐卸载新的模型副本，但是不可以低于调度策略规定的值
Instance utilization and ARIMA gap (LT-UA)方法：考虑模型实例的使用率，当使用率增大超过某一个阈值时按照新的调度策略逐渐加载新的模型副本，可以超过调度策略规定的值，相反，当使用率减少低于某一个阈值时按照新的调度策略逐渐卸载新的模型副本，可以低于调度策略规定的值。这个策略可以在预测不准的情况下，更智能的进行扩缩容">
  <meta property="og:locale" content="en_gb">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-03-27T14:32:49+08:00">
    <meta property="article:modified_time" content="2025-03-27T14:32:49+08:00">


    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="LLM Scheduling">
  <meta name="twitter:description" content="有关大模型任务调度的讨论 大模型具有一些内在的特性，导致在大模型任务调度方面会有一些新的挑战。
冷启动问题 大模型的特点之一是参数规模非常大，常见的175B,670B等等。
当系统的请求量变化时，需要针对集群开发新的调度策略，其中就包括改变集群中不同模型副本的数量，也就是进行扩缩容操作。然而由于大模型的参数规模大，导致在gpu上加载新模型的开销非常大，甚至对于大多数大模型来说，单张gpu无法达到推理的显存需求，需要在好几张gpu上加载大模型，进一步导致大模型的冷启动问题。不同参数规模的大模型加载开销不同，但基本都要超过10分钟的开销。
针对大模型的冷启动问题常用的解决思路如下
预测流派 调度的根本原因在于系统请求量的变化，预测流派使用EWMA，ARIMA等方法粗粒度的提前预测下一时段的系统请求量，并提前计算好新的调度策略。
粗粒度是按照小时来作为时间段的单位，预测下一时段（几个小时）的请求量是多少，然后在下一个时段中慢慢进行模型的加载（因为相比于小时，10min还是比较短的时间）。由于是提前预测好，并不是系统突然的请求量burst，所以可以消除冷启动带来的影响（等到请求量增大时，已经提前加载好了大模型）
预测流派需要对系统请求量的变化有相对准确的预测，如果不准确会导致资源的浪费（多加载了大模型）/SLO 冲突（少加载了大模型）
相关文献《Serving Models, Fast and Slow:Optimizing Heterogeneous LLM Inferencing Workloads at Scale》
这个paper中还详细讨论了在下一个时段中慢慢进行模型加载的策略
Naive方法：在得出新的调度策略后，直接进行改变
Instance Utilization (LT-U)方法：考虑模型实例的使用率，当使用率增大超过某一个阈值时按照新的调度策略逐渐加载新的模型副本，但是不可以超过调度策略规定的值，相反，当使用率减少低于某一个阈值时按照新的调度策略逐渐卸载新的模型副本，但是不可以低于调度策略规定的值
Instance utilization and ARIMA gap (LT-UA)方法：考虑模型实例的使用率，当使用率增大超过某一个阈值时按照新的调度策略逐渐加载新的模型副本，可以超过调度策略规定的值，相反，当使用率减少低于某一个阈值时按照新的调度策略逐渐卸载新的模型副本，可以低于调度策略规定的值。这个策略可以在预测不准的情况下，更智能的进行扩缩容">


    

    <link rel="canonical" href="https://theflash010.github.io/posts/llm-scheduling/">
    <link href="/style.min.2d921c18cf1ec555ffc03d59a8adc211c402c68c930c27d6a0c306ab175a8d09.css" rel="stylesheet">
    <link href="/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css" rel="stylesheet">

    
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/icons/favicon-16x16.png">
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg">
    <link rel="shortcut icon" href="/favicon.ico">




<link rel="manifest" href="https://theflash010.github.io/site.webmanifest">

<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="msapplication-TileColor" content="#2d89ef">
<meta name="theme-color" content="#434648">

    
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">

    
    
    
</head>
<body data-theme = "auto" class="notransition">

<script src="/js/theme.min.8961c317c5b88b953fe27525839672c9343f1058ab044696ca225656c8ba2ab0.js" integrity="sha256-iWHDF8W4i5U/4nUlg5ZyyTQ/EFirBEaWyiJWVsi6KrA="></script>

<div class="navbar" role="navigation">
    <nav class="menu" aria-label="Main Navigation">
        <a href="https://theflash010.github.io/" class="logo">
            <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" 
viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" 
stroke-linejoin="round" class="feather feather-home">
<title>Home</title>
<path d="M3 9l9-7 9 7v11a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"></path>
<polyline points="9 22 9 12 15 12 15 22"></polyline>
</svg>
        </a>
        <input type="checkbox" id="menu-trigger" class="menu-trigger" />
        <label for="menu-trigger">
            <span class="menu-icon">
                <svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7L3.40726 7"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488L3.49301 3.51488"></path><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"></path><path stroke-linecap="round" stroke-linejoin="round" d="M0.5 12.5V1.5C0.5 0.947715 0.947715 0.5 1.5 0.5H12.5C13.0523 0.5 13.5 0.947715 13.5 1.5V12.5C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C0.947715 13.5 0.5 13.0523 0.5 12.5Z"></path></svg>
            </span>
        </label>

        <div class="trigger">
            <ul class="trigger-container">
                
                
                <li>
                    <a class="menu-link " href="/">
                        Home
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link active" href="/posts/">
                        Posts
                    </a>
                    
                </li>
                
                <li>
                    <a class="menu-link " href="/pages/about/">
                        About
                    </a>
                    
                </li>
                
                <li class="menu-separator">
                    <span>|</span>
                </li>
                
                
            </ul>
            <a id="mode" href="#">
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
                <svg xmlns="http://www.w3.org/2000/svg" class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1">
<title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></circle><line x1="7" y1="0.5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="0.5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"></line><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"></line></g></svg>
            </a>
        </div>
    </nav>
</div>

<div class="wrapper post">
    <main class="page-content" aria-label="Content">
        <article>
            <header class="header">
                <h1 class="header-title">LLM Scheduling</h1>
                
                
                
                <div class="post-meta">
                    <time datetime="2025-03-27T14:32:49&#43;08:00" itemprop="datePublished"> 27 Mar 2025 </time>
                </div>
                
            </header>
            
    
    <details class="toc" ZgotmplZ>
        <summary><b>Table of Contents</b></summary>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#冷启动问题">冷启动问题</a>
      <ul>
        <li><a href="#预测流派">预测流派</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </details>
            <div class="page-content">
                <h1 id="有关大模型任务调度的讨论">有关大模型任务调度的讨论</h1>
<p>大模型具有一些内在的特性，导致在大模型任务调度方面会有一些新的挑战。</p>
<h2 id="冷启动问题">冷启动问题</h2>
<p>大模型的特点之一是参数规模非常大，常见的175B,670B等等。</p>
<p>当系统的请求量变化时，需要针对集群开发新的调度策略，其中就包括改变集群中不同模型副本的数量，也就是进行<strong>扩缩容</strong>操作。然而由于大模型的参数规模大，导致在gpu上加载新模型的开销非常大，甚至对于大多数大模型来说，单张gpu无法达到推理的显存需求，需要在好几张gpu上加载大模型，进一步导致大模型的冷启动问题。不同参数规模的大模型加载开销不同，但基本都要超过10分钟的开销。</p>
<p>针对大模型的冷启动问题常用的解决思路如下</p>
<h3 id="预测流派">预测流派</h3>
<p>调度的根本原因在于系统请求量的变化，预测流派使用EWMA，ARIMA等方法<font color='red'>粗粒度</font>的提前预测下一时段的系统请求量，并提前计算好新的调度策略。</p>
<p><font color='red'>粗粒度</font>是按照小时来作为时间段的单位，预测下一时段（几个小时）的请求量是多少，然后在下一个时段中慢慢进行模型的加载（因为相比于小时，10min还是比较短的时间）。由于是提前预测好，并不是系统突然的请求量burst，所以可以消除冷启动带来的影响（等到请求量增大时，已经提前加载好了大模型）</p>
<p>预测流派需要对系统请求量的变化有相对准确的预测，如果不准确会导致资源的浪费（多加载了大模型）/SLO 冲突（少加载了大模型）</p>
<p>相关文献<em><strong>《Serving Models, Fast and Slow:Optimizing Heterogeneous LLM Inferencing Workloads at Scale》</strong></em></p>
<p>这个paper中还详细讨论了在下一个时段中慢慢进行模型加载的策略</p>
<p>Naive方法：在得出新的调度策略后，直接进行改变</p>
<p>Instance Utilization (LT-U)方法：考虑模型实例的使用率，当使用率增大超过某一个阈值时按照新的调度策略逐渐加载新的模型副本，但是不可以超过调度策略规定的值，相反，当使用率减少低于某一个阈值时按照新的调度策略逐渐卸载新的模型副本，但是不可以低于调度策略规定的值</p>
<p>Instance utilization and ARIMA gap (LT-UA)方法：考虑模型实例的使用率，当使用率增大超过某一个阈值时按照新的调度策略逐渐加载新的模型副本，可以超过调度策略规定的值，相反，当使用率减少低于某一个阈值时按照新的调度策略逐渐卸载新的模型副本，可以低于调度策略规定的值。这个策略可以在预测不准的情况下，更智能的进行扩缩容</p>

            </div>
        </article></main>
</div>
<footer class="footer">
    <span class="footer_item"> </span>
    &nbsp;

    <div class="footer_social-icons">
<a href="https://github.com/theflash010" target="_blank" rel="noopener noreferrer me"
    title="Github">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
</a>
<a href="https://space.bilibili.com/106734387?spm_id_from=333.1007.0.0" target="_blank" rel="noopener noreferrer me"
    title="Bilibili">
    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" xmlns="http://www.w3.org/2000/svg">
    <rect x="1.3333" y="6" width="21.333" height="15.333" rx="4" ry="4"/>
    <path d="m8 12.4v1.2"/>
    <path d="m16 12.4v1.2"/>
    <path d="m5.8853 2.6667 2.6667 2.6667"/>
    <path d="m18.115 2.6667-2.6667 2.6667"/>
</svg>
</a>
<a href="/index.xml" target="_blank" rel="noopener noreferrer me"
    title="Rss">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 11a9 9 0 0 1 9 9" />
    <path d="M4 4a16 16 0 0 1 16 16" />
    <circle cx="5" cy="19" r="1" />
</svg>
</a>
</div>
    <small class="footer_copyright">
        © 2025 Nan Z.
        Powered by <a href="https://github.com/hugo-sid/hugo-blog-awesome" target="_blank" rel="noopener">Hugo blog awesome</a>.
    </small>
</footer><a href="#" title="Go to top" id="totop">
    <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" fill="currentColor" stroke="currentColor" viewBox="0 96 960 960">
    <path d="M283 704.739 234.261 656 480 410.261 725.739 656 677 704.739l-197-197-197 197Z"/>
</svg>

</a>


    




    
    
        
    

    
    
        
    



    
    <script src="https://theflash010.github.io/js/main.min.35f435a5d8eac613c52daa28d8af544a4512337d3e95236e4a4978417b8dcb2f.js" integrity="sha256-NfQ1pdjqxhPFLaoo2K9USkUSM30&#43;lSNuSkl4QXuNyy8="></script>

    

</body>
</html>
